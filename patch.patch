 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/migration/bidirectional_sync.py b/migration/bidirectional_sync.py
index ac3ad851d5f1d3d712759860c65faed1a4598837..020a9c323a31c1fca9ec63f5b88419921f9ffc14 100644
--- a/migration/bidirectional_sync.py
+++ b/migration/bidirectional_sync.py
@@ -207,133 +207,154 @@ class BidirectionalSyncEngine:
             # Get epic data
             cursor = conn.execute("""
                 SELECT * FROM framework_epics 
                 WHERE epic_key = ? AND deleted_at IS NULL
             """, (epic_key,))
             
             epic_row = cursor.fetchone()
             if not epic_row:
                 return None
             
             epic_data = dict(epic_row)
             
             # Get tasks for this epic
             cursor = conn.execute("""
                 SELECT * FROM framework_tasks 
                 WHERE epic_id = ? AND status != 'deleted'
                 ORDER BY task_sequence, task_key
             """, (epic_data['id'],))
             
             tasks = [dict(row) for row in cursor.fetchall()]
             epic_data['tasks'] = tasks
             
             return epic_data
     
     def insert_epic_to_db(self, epic_data: Dict[str, Any]) -> int:
-        """Insert new epic into database."""
+        """Insert new epic into database using a single connection."""
         with self.get_database_connection() as conn:
+            # Increase timeout for complex operations
+            conn.execute("PRAGMA busy_timeout=60000")
+
             # Prepare epic fields
             epic_key = epic_data.get('id') or epic_data.get('epic_key', '')
             name = epic_data.get('name', '')
             summary = epic_data.get('summary', epic_data.get('description', ''))
             duration_desc = epic_data.get('duration', '')
-            
+
             # JSON fields
             goals = json.dumps(epic_data.get('goals', []), ensure_ascii=False)
             definition_of_done = json.dumps(epic_data.get('definition_of_done', []), ensure_ascii=False)
             labels = json.dumps(epic_data.get('labels', []), ensure_ascii=False)
-            
+
             # Calculate dates using enrichment engine
             enriched = self.enrichment_engine.enrich_epic(epic_data)
             calc_fields = enriched.get('calculated_fields', {})
-            
+
             # Insert epic
             cursor = conn.execute("""
                 INSERT INTO framework_epics (
                     epic_key, name, summary, duration_description,
                     goals, definition_of_done, labels,
                     planned_start_date, planned_end_date, calculated_duration_days,
                     tdd_enabled, methodology,
                     performance_constraints, quality_gates, automation_hooks, checklist_epic_level,
                     sync_status, json_checksum, created_at, updated_at
                 ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'synced', ?, ?, ?)
             """, (
                 epic_key, name, summary, duration_desc,
                 goals, definition_of_done, labels,
                 calc_fields.get('planned_start_date'), calc_fields.get('planned_end_date'),
                 calc_fields.get('calculated_duration_days', 0),
                 epic_data.get('tdd_enabled', True), epic_data.get('methodology', 'Test-Driven Development'),
                 json.dumps(epic_data.get('performance_constraints', {}), ensure_ascii=False),
                 json.dumps(epic_data.get('quality_gates', {}), ensure_ascii=False),
                 json.dumps(epic_data.get('automation_hooks', {}), ensure_ascii=False),
                 json.dumps(epic_data.get('checklist_epic_level', []), ensure_ascii=False),
                 self.calculate_checksum(epic_data),
                 datetime.now().isoformat(), datetime.now().isoformat()
             ))
-            
+
             epic_id = cursor.lastrowid
-            
-            # Insert tasks
-            self.insert_tasks_to_db(epic_id, epic_data.get('tasks', []))
-            
+
+            # Insert tasks using the same connection
+            self.insert_tasks_to_db(epic_id, epic_data.get('tasks', []), conn=conn)
+
             conn.commit()
             return epic_id
-    
-    def insert_tasks_to_db(self, epic_id: int, tasks: List[Dict[str, Any]]):
-        """Insert tasks for an epic into database."""
-        with self.get_database_connection() as conn:
-            for i, task in enumerate(tasks):
-                task_key = task.get('id', f"{i+1}")
-                title = task.get('title', '')
-                description = task.get('description', '')
-                tdd_phase = task.get('tdd_phase')
-                estimate_minutes = task.get('estimate_minutes', 60)
-                story_points = task.get('story_points', 1)
-                branch = task.get('branch', '')
-                
-                # JSON fields
-                test_specs = json.dumps(task.get('test_specs', []), ensure_ascii=False)
-                acceptance_criteria = json.dumps(task.get('acceptance_criteria', []), ensure_ascii=False)
-                deliverables = json.dumps(task.get('deliverables', []), ensure_ascii=False)
-                files_touched = json.dumps(task.get('files_touched', []), ensure_ascii=False)
-                test_plan = json.dumps(task.get('test_plan', []), ensure_ascii=False)
-                
-                conn.execute("""
-                    INSERT INTO framework_tasks (
-                        task_key, epic_id, title, description, tdd_phase,
-                        estimate_minutes, story_points, github_branch,
-                        test_specs, acceptance_criteria, deliverables, files_touched, test_plan,
-                        risk, mitigation, tdd_skip_reason,
-                        task_sequence, created_at, updated_at
-                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
-                """, (
-                    task_key, epic_id, title, description, tdd_phase,
-                    estimate_minutes, story_points, branch,
-                    test_specs, acceptance_criteria, deliverables, files_touched, test_plan,
-                    task.get('risk', ''), task.get('mitigation', ''), task.get('tdd_skip_reason', ''),
-                    i + 1, datetime.now().isoformat(), datetime.now().isoformat()
-                ))
+
+    def insert_tasks_to_db(self, epic_id: int, tasks: List[Dict[str, Any]], conn: sqlite3.Connection | None = None):
+        """Insert tasks for an epic into database.
+
+        Uses batch insertion and supports connection reuse to avoid nested
+        transactions that could lead to deadlocks.
+        """
+
+        # Prepare data for batch insertion
+        task_rows: List[Tuple[Any, ...]] = []
+        for i, task in enumerate(tasks):
+            task_key = task.get('id', f"{i+1}")
+            title = task.get('title', '')
+            description = task.get('description', '')
+            tdd_phase = task.get('tdd_phase')
+            estimate_minutes = task.get('estimate_minutes', 60)
+            story_points = task.get('story_points', 1)
+            branch = task.get('branch', '')
+
+            # JSON fields
+            test_specs = json.dumps(task.get('test_specs', []), ensure_ascii=False)
+            acceptance_criteria = json.dumps(task.get('acceptance_criteria', []), ensure_ascii=False)
+            deliverables = json.dumps(task.get('deliverables', []), ensure_ascii=False)
+            files_touched = json.dumps(task.get('files_touched', []), ensure_ascii=False)
+            test_plan = json.dumps(task.get('test_plan', []), ensure_ascii=False)
+
+            task_rows.append((
+                task_key, epic_id, title, description, tdd_phase,
+                estimate_minutes, story_points, branch,
+                test_specs, acceptance_criteria, deliverables, files_touched, test_plan,
+                task.get('risk', ''), task.get('mitigation', ''), task.get('tdd_skip_reason', ''),
+                i + 1, datetime.now().isoformat(), datetime.now().isoformat()
+            ))
+
+        if not task_rows:
+            return
+
+        insert_sql = """
+            INSERT INTO framework_tasks (
+                task_key, epic_id, title, description, tdd_phase,
+                estimate_minutes, story_points, github_branch,
+                test_specs, acceptance_criteria, deliverables, files_touched, test_plan,
+                risk, mitigation, tdd_skip_reason,
+                task_sequence, created_at, updated_at
+            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
+        """
+
+        if conn is None:
+            with self.get_database_connection() as own_conn:
+                own_conn.executemany(insert_sql, task_rows)
+                own_conn.commit()
+        else:
+            conn.executemany(insert_sql, task_rows)
     
     def sync_json_to_db(self, epic_data: Dict[str, Any], file_path: str = "") -> SyncResult:
         """Synchronize JSON data to database."""
         start_time = datetime.now()
         epic_key = epic_data.get('id') or epic_data.get('epic_key', '')
         
         result = SyncResult(
             success=False,
             epic_key=epic_key,
             direction=SyncDirection.JSON_TO_DB,
             changes_made=[],
             conflicts_detected=[],
             conflicts_resolved=[],
             errors=[],
             duration_ms=0
         )
         
         try:
             if not epic_key:
                 result.errors.append("Epic key not found in JSON data")
                 return result
             
             # Check if epic exists
             if self.epic_exists_in_db(epic_key):
                 result.changes_made.append(f"Epic {epic_key} already exists - update logic needed")
 
EOF
)