 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/DatabaseManager_methods.txt b/DatabaseManager_methods.txt
new file mode 100644
index 0000000000000000000000000000000000000000..f44540e3330d4396f3510f36fa67d1b55d5c8d1d
--- /dev/null
+++ b/DatabaseManager_methods.txt
@@ -0,0 +1,55 @@
+352:    def get_paginated_results(
+432:    def get_cursor_paginated_results(
+458:    def get_keyset_paginated_results(
+571:    def get_connection(
+614:    def release_connection(self, connection: Union[Connection, SQLiteConnection]) -> None:
+634:    def transaction(
+714:    def delete_with_transaction(
+764:    def delete_cascade_safe(
+834:    def execute_query(
+859:    def get_epics(
+948:    def get_all_epics(self) -> List[Dict[str, Any]]:
+954:    def get_tasks(
+1061:    def get_all_tasks(self, epic_id: Optional[int] = None) -> List[Dict[str, Any]]:
+1067:    def get_timer_sessions(self, days: int = 30) -> List[Dict[str, Any]]:
+1097:    def get_user_stats(self, user_id: int = 1) -> Dict[str, Any]:
+1165:    def get_achievements(self, user_id: int = 1) -> List[Dict[str, Any]]:
+1191:    def update_task_status(self, task_id: int, status: str, tdd_phase: Optional[str] = None) -> bool:
+1236:    def create_timer_session(self, task_id: Optional[int], duration_minutes: int, 
+1288:    def get_epic_progress(self, epic_id: int) -> Dict[str, Any]:
+1398:    def check_database_health(self) -> Dict[str, Any]:
+1453:    def format_database_datetime(self, dt_string: str, format_type: str = "full") -> str:
+1479:    def get_formatted_epic_data(self) -> List[Dict[str, Any]]:
+1498:    def get_formatted_timer_sessions(self, days: int = 30) -> List[Dict[str, Any]]:
+1517:    def clear_cache(self, cache_pattern: Optional[str] = None) -> bool:
+1541:    def get_cache_stats(self) -> Dict[str, Any]:
+1549:    def get_query_statistics(self) -> Dict[str, Any]:
+1570:    def optimize_database(self) -> Dict[str, Any]:
+1596:    def create_backup(self, backup_path: Optional[str] = None) -> str:
+1614:    def restore_backup(self, backup_path: str, verify: bool = True) -> bool:
+1638:    def get_productivity_stats(self, days: int = 7) -> Dict[str, Any]:
+1732:    def get_daily_summary(self) -> Dict[str, Any]:
+1854:    def get_pending_notifications(self) -> List[Dict[str, Any]]:
+1901:    def get_user_achievements(self, limit: int = 10) -> List[Dict[str, Any]]:
+2006:    def create_task(self, title: str, epic_id: int, description: str = "", 
+2056:    def update_task(
+2135:    def delete_task(self, task_id: int, soft_delete: bool = True) -> bool:
+2180:    def get_kanban_tasks(self) -> Dict[str, List[Dict[str, Any]]]:
+2219:    def get_task_statistics(self) -> Dict[str, int]:
+2272:    def calculate_epic_duration(self, epic_id: int) -> float:
+2333:    def update_duration_description(self, epic_id: int, description: str) -> bool:
+2387:    def get_epic_timeline(self, epic_id: int) -> Dict[str, Any]:
+2477:    def validate_date_consistency(self, epic_id: int) -> bool:
+2594:    def get_projects(
+2702:    def get_all_projects(self, include_inactive: bool = False) -> List[Dict[str, Any]]:
+2708:    def get_epics_with_hierarchy(self, project_id: Optional[int] = None,
+2805:    def get_all_epics_with_hierarchy(self, project_id: Optional[int] = None) -> List[Dict[str, Any]]:
+2811:    def get_hierarchy_overview(self) -> List[Dict[str, Any]]:
+2845:    def get_project_dashboard(self, project_id: Optional[int] = None) -> List[Dict[str, Any]]:
+2896:    def create_project(
+2976:    def update_epic_project(self, epic_id: int, project_id: int) -> bool:
+3011:    def get_project_by_key(self, project_key: str) -> Optional[Dict[str, Any]]:
+3050:    def update_project(self, project_id: int, **fields: Any) -> bool:
+3117:    def delete_project(self, project_id: int, soft_delete: bool = True) -> bool:
+3162:    def close(self) -> None:
+3187:def dict_rows(connection: SQLiteConnection) -> Iterator[None]:
diff --git a/database_migration_script.py b/database_migration_script.py
new file mode 100644
index 0000000000000000000000000000000000000000..9f09bf069f5ffd31bfa5c8a4a355c22ce937f7ed
--- /dev/null
+++ b/database_migration_script.py
@@ -0,0 +1,167 @@
+import os
+import shutil
+import subprocess
+
+# === MIGRATION MAP ===
+MIGRATION_MAP = {
+    # === EPIC OPERATIONS ===
+    "DatabaseManager().get_epics()": {
+        "new_api": "from streamlit_extension.database import list_epics; list_epics()",
+        "compatibility": "FULL",
+        "notes": "Direct replacement"
+    },
+    "DatabaseManager().get_epic(epic_id)": {
+        "new_api": "from streamlit_extension.database.queries import get_epic_by_id; get_epic_by_id(epic_id)",
+        "compatibility": "NEEDS_VERIFICATION",
+        "notes": "Check if get_epic_by_id exists"
+    },
+    "DatabaseManager().create_epic(data)": {
+        "new_api": "from streamlit_extension.services import ServiceContainer; ServiceContainer().get_epic_service().create(data)",
+        "compatibility": "FULL",
+        "notes": "Via service layer"
+    },
+
+    # === TASK OPERATIONS ===
+    "DatabaseManager().get_tasks()": {
+        "new_api": "from streamlit_extension.database import list_tasks; list_tasks()",
+        "compatibility": "FULL",
+        "notes": "Direct replacement"
+    },
+    "DatabaseManager().create_task(data)": {
+        "new_api": "from streamlit_extension.services import ServiceContainer; ServiceContainer().get_task_service().create(data)",
+        "compatibility": "FULL",
+        "notes": "Via service layer"
+    },
+
+    # === CONNECTION MANAGEMENT ===
+    "DatabaseManager().get_connection()": {
+        "new_api": "from streamlit_extension.database import get_connection; get_connection()",
+        "compatibility": "FULL",
+        "notes": "Direct replacement"
+    },
+    "DatabaseManager(db_path='custom.db')": {
+        "new_api": "# HYBRID: Keep legacy for custom paths",
+        "compatibility": "HYBRID_NEEDED",
+        "notes": "New API doesn't support custom db_path"
+    },
+
+    # === TRANSACTION MANAGEMENT ===
+    "DatabaseManager().transaction()": {
+        "new_api": "from streamlit_extension.database import transaction; transaction()",
+        "compatibility": "FULL",
+        "notes": "Context manager available"
+    },
+
+    # === ANALYTICS ===
+    "DatabaseManager().get_analytics()": {
+        "new_api": "from streamlit_extension.services import ServiceContainer; ServiceContainer().get_analytics_service().get_metrics()",
+        "compatibility": "NEEDS_VERIFICATION",
+        "notes": "Check analytics service methods"
+    },
+
+    # === COMPLEX/BULK OPERATIONS ===
+    "DatabaseManager().bulk_create_tasks()": {
+        "new_api": "# HYBRID: No modular equivalent",
+        "compatibility": "HYBRID_NEEDED",
+        "notes": "Keep legacy DatabaseManager for bulk ops"
+    },
+
+    # === VALIDATION ===
+    "DatabaseManager().validate_epic_data()": {
+        "new_api": "# HYBRID: Validation not exposed in modular API",
+        "compatibility": "HYBRID_NEEDED",
+        "notes": "Keep legacy for validation methods"
+    }
+}
+
+# === FILE COMPLEXITY LEVELS ===
+FILE_COMPLEXITY_LEVELS = {
+    "SIMPLE": [
+        "streamlit_extension/pages/analytics.py",
+        "streamlit_extension/pages/gantt.py",
+        "streamlit_extension/pages/settings.py"
+    ],
+    "MODERATE": [
+        "streamlit_extension/pages/projects.py",
+        "streamlit_extension/pages/kanban.py",
+        "streamlit_extension/pages/timer.py"
+    ],
+    "COMPLEX": [
+        "streamlit_extension/pages/projeto_wizard.py",
+        "streamlit_extension/models/database.py",
+        "streamlit_extension/models/base.py",
+        "streamlit_extension/utils/cached_database.py"
+    ]
+}
+
+# === MIGRATION FUNCTIONS ===
+
+def apply_transformations(filepath, transformations):
+    for t in transformations:
+        subprocess.run(['sed', '-i', t['find'], filepath])
+
+def apply_simple_transformations(filepath):
+    transformations = [
+        {
+            'find': 's/from streamlit_extension.utils.database import DatabaseManager/from streamlit_extension.database import list_epics, list_tasks, get_connection/'
+        },
+        {
+            'find': 's/db_manager = DatabaseManager()/# Migrated to modular API calls/'
+        },
+        {
+            'find': 's/db_manager\\.get_epics()/list_epics()/'
+        },
+        {
+            'find': 's/db_manager\\.get_tasks()/list_tasks()/'
+        },
+    ]
+    apply_transformations(filepath, transformations)
+
+def validate_migration(filepath, backup_path):
+    print(f"üß™ VALIDATING: {filepath}")
+    result = subprocess.run(['python3', '-m', 'py_compile', filepath])
+    if result.returncode != 0:
+        print("‚ùå SYNTAX ERROR, restoring backup")
+        shutil.copy(backup_path, filepath)
+        return False
+    try:
+        import importlib.util
+        spec = importlib.util.spec_from_file_location('test_module', filepath)
+        module = importlib.util.module_from_spec(spec)
+        spec.loader.exec_module(module)
+        print("‚úÖ IMPORTS OK")
+    except Exception as e:
+        print(f"‚ùå IMPORT ERROR: {e}")
+        shutil.copy(backup_path, filepath)
+        return False
+    return True
+
+if __name__ == '__main__':
+    SIMPLE_FILES = FILE_COMPLEXITY_LEVELS['SIMPLE']
+    for filepath in SIMPLE_FILES:
+        print(f'üîÑ Migrating SIMPLE: {filepath}')
+        backup_path = f"{filepath}.backup_before_migration"
+        shutil.copy(filepath, backup_path)
+        apply_simple_transformations(filepath)
+        if not validate_migration(filepath, backup_path):
+            print('‚ùå Migration failed, restored original')
+        else:
+            print('‚úÖ Migration succeeded')
+
+    # Integration test
+    print('\nRunning integration checks...')
+    try:
+        from streamlit_extension.database import list_epics, list_tasks
+        epics = list_epics()
+        tasks = list_tasks()
+        print(f'‚úÖ Database operations work: {len(epics)} epics, {len(tasks)} tasks')
+    except Exception as e:
+        print(f'‚ùå Database operations failed: {e}')
+
+    try:
+        from streamlit_extension.services import ServiceContainer
+        container = ServiceContainer()
+        epic_service = container.get_epic_service()
+        print('‚úÖ Service layer works')
+    except Exception as e:
+        print(f'‚ùå Service layer failed: {e}')
diff --git a/streamlit_extension/pages/analytics.py b/streamlit_extension/pages/analytics.py
index d11ad5a4d4ddd7289de2101a3c68ead1c9e1035b..69fdc5dbc52a4af16eb15364e2d5cc76e542ec50 100644
--- a/streamlit_extension/pages/analytics.py
+++ b/streamlit_extension/pages/analytics.py
@@ -47,51 +47,51 @@ try:
     import pandas as pd
     PANDAS_AVAILABLE = True
 except ImportError:
     PANDAS_AVAILABLE = False
     pd = None  # type: ignore
 
 # --- Autentica√ß√£o -------------------------------------------------------------
 # Import absoluto (corrige erro cr√≠tico do relat√≥rio):
 try:
     from streamlit_extension.auth.middleware import init_protected_page, require_auth
 except ImportError:
     # Fallback seguro em desenvolvimento: mant√©m p√°gina acess√≠vel
     def init_protected_page(title: str, *, layout: str = "wide") -> None:
         st.set_page_config(page_title=title, layout=layout)
 
     def require_auth(role: Optional[str] = None):  # type: ignore
         def _decorator(fn):
             def _inner(*args, **kwargs):
                 # Em produ√ß√£o real, este fallback n√£o deve ser usado.
                 return fn(*args, **kwargs)
             return _inner
         return _decorator
 
 # Local imports
 try:
-    from streamlit_extension.utils.database import DatabaseManager
+    from streamlit_extension.database import list_epics, list_tasks, get_connection
     from streamlit_extension.utils.security import (
         sanitize_display, validate_form, check_rate_limit,
         security_manager,
     )
     from streamlit_extension.utils.exception_handler import (
         handle_streamlit_exceptions, streamlit_error_boundary, safe_streamlit_operation,
     )
     from streamlit_extension.config import load_config
     DATABASE_UTILS_AVAILABLE = True
 except ImportError:
     DatabaseManager = load_config = None  # type: ignore
     sanitize_display = validate_form = None  # type: ignore
     check_rate_limit = security_manager = None  # type: ignore
 
     # Fallbacks seguros: no-op decorators/utilit√°rios
     def handle_streamlit_exceptions(*args, **kwargs):  # type: ignore
         def _wrap(func):
             return func
         return _wrap
 
     def streamlit_error_boundary(*args, **kwargs):  # type: ignore
         def _wrap(func):
             return func
         return _wrap
 
@@ -263,76 +263,76 @@ def optimize_database_queries(db_manager: "DatabaseManager", days: int, filters:
             spinner_ctx = st.spinner("Optimizing data queries...")
         else:
             # Dummy context manager
             class _NullCtx:
                 def __enter__(self): return None
                 def __exit__(self, exc_type, exc, tb): return False
             spinner_ctx = _NullCtx()
 
         with spinner_ctx:
             # --- Sessions -----------------------------------------------------
             sessions = _ensure_dict_list(
                 db_manager.get_timer_sessions(days)  # type: ignore[arg-type]
             )
             if filters:
                 fr = filters.get("focus_range")
                 if fr and fr != (1, 10):
                     mn, mx = fr
                     sessions = [s for s in sessions if (s.get("focus_rating") is None or mn <= s.get("focus_rating", 0) <= mx)]
                 stypes = filters.get("selected_session_types")
                 if stypes:
                     allowed = set(stypes)
                     sessions = [s for s in sessions if s.get("session_type") in allowed]
             query_results["timer_sessions"] = sessions
 
             # --- Tasks / Epics ------------------------------------------------
-            tasks = _ensure_dict_list(db_manager.get_tasks())
-            epics = _ensure_dict_list(db_manager.get_epics())
+            tasks = _ensure_dict_list(list_tasks())
+            epics = _ensure_dict_list(list_epics())
             if filters:
                 selected_epics = set(filters.get("selected_epics") or [])
                 if selected_epics:
                     tasks = [t for t in tasks if t.get("epic_name") in selected_epics]
                     epics = [e for e in epics if e.get("name") in selected_epics]
                 tdd = set(filters.get("selected_tdd_phases") or [])
                 if tdd:
                     tasks = [t for t in tasks if t.get("tdd_phase") in tdd]
             query_results["tasks"] = tasks
             query_results["epics"] = epics
 
             # --- User Stats ---------------------------------------------------
             raw_stats = db_manager.get_user_stats()
             query_results["user_stats"] = _normalize_user_stats(raw_stats)
 
         return query_results
 
     except Exception as e:
         if STREAMLIT_AVAILABLE:
             st.error(f"Database query optimization failed: {e}")
         return {
             "timer_sessions": _ensure_dict_list(db_manager.get_timer_sessions(days)),  # type: ignore[arg-type]
-            "tasks": _ensure_dict_list(db_manager.get_tasks()),
-            "epics": _ensure_dict_list(db_manager.get_epics()),
+            "tasks": _ensure_dict_list(list_tasks()),
+            "epics": _ensure_dict_list(list_epics()),
             "user_stats": _normalize_user_stats(db_manager.get_user_stats()),
         }
 
 
 # ==============================
 #   P√°gina principal (render)
 # ==============================
 
 def _apply_chart_theme(fig) -> None:
     """Aplica template de tema se definido via sidebar."""
     if not STREAMLIT_AVAILABLE:
         return
     template = getattr(st.session_state, "chart_settings", {}).get("theme", None)
     if template:
         fig.update_layout(template=template)
 
 @require_auth()  # Protege a p√°gina; em dev, o fallback acima permite acesso
 @handle_streamlit_exceptions(show_error=True, attempt_recovery=True)
 def render_analytics_page():
     """Main analytics page with modular architecture."""
     if not STREAMLIT_AVAILABLE:
         return {"error": "Streamlit not available"}
 
     init_protected_page("üìä Analytics Dashboard", layout="wide")
 
@@ -426,51 +426,51 @@ def _render_time_range_selector() -> int:
         "Last 6 months": 180,
         "Last year": 365,
         "All time": 9999,
         "Custom range": 0,
     }
     selected_range = st.sidebar.selectbox("Select time range", list(time_options.keys()), index=2)
     if selected_range == "Custom range":
         col1, col2 = st.sidebar.columns(2)
         with col1:
             start_date = st.date_input("From", value=datetime.now() - timedelta(days=30))
         with col2:
             end_date = st.date_input("To", value=datetime.now())
         days = (end_date - start_date).days + 1
         st.sidebar.caption(f"Period: {days} days")
     else:
         days = time_options[selected_range]
     return days
 
 
 def _render_advanced_filters(db_manager: "DatabaseManager", days: int) -> Dict[str, Any]:
     st.sidebar.markdown("## üîç Advanced Filters")
 
     selected_epics: List[str] = []
     if st.sidebar.checkbox("Filter by Epic", value=False):
         try:
-            all_epics = db_manager.get_epics()
+            all_epics = list_epics()
             epic_names = [epic.get("name", "Unknown") for epic in all_epics]
             selected_epics = st.sidebar.multiselect("Select Epics", epic_names)
         except Exception:
             st.sidebar.warning("Could not load epics")
 
     focus_range = (1, 10)
     if st.sidebar.checkbox("Filter by Focus Level", value=False):
         focus_range = st.sidebar.slider("Focus Rating Range", min_value=1, max_value=10, value=(1, 10), step=1)
 
     selected_tdd_phases: List[str] = []
     if st.sidebar.checkbox("Filter by TDD Phase", value=False):
         tdd_phases = ["red", "green", "refactor"]
         selected_tdd_phases = st.sidebar.multiselect("Select TDD Phases", tdd_phases)
 
     selected_session_types: List[str] = []
     if st.sidebar.checkbox("Filter by Session Type", value=False):
         session_types = ["focus_session", "short_break", "long_break", "custom"]
         selected_session_types = st.sidebar.multiselect("Select Session Types", session_types)
 
     filters = {
         "days": days,
         "selected_epics": selected_epics,
         "focus_range": focus_range,
         "selected_tdd_phases": selected_tdd_phases,
         "selected_session_types": selected_session_types,
diff --git a/streamlit_extension/pages/gantt.py b/streamlit_extension/pages/gantt.py
index 4fe437346847624277d9ccae63c3f5890bde4ab0..2b266d487b8e5ee214dff1f0e9a05ac08f179771 100644
--- a/streamlit_extension/pages/gantt.py
+++ b/streamlit_extension/pages/gantt.py
@@ -26,51 +26,51 @@ try:
 except ImportError:
     STREAMLIT_AVAILABLE = False  # type: ignore
     st = None  # type: ignore
 
 try:
     import plotly.express as px
     import plotly.graph_objects as go
     from plotly.subplots import make_subplots
     import plotly.figure_factory as ff
     PLOTLY_AVAILABLE = True
 except ImportError:
     PLOTLY_AVAILABLE = False  # type: ignore
     px = go = make_subplots = ff = None  # type: ignore
 
 try:
     import pandas as pd
     PANDAS_AVAILABLE = True
 except ImportError:
     PANDAS_AVAILABLE = False  # type: ignore
     pd = None  # type: ignore
 
 # --- Depend√™ncias locais -------------------------------------------------------
 try:
     # Config & DB (usar assinatura consistente com Analytics)
     from streamlit_extension.config import load_config
-    from streamlit_extension.utils.database import DatabaseManager
+    from streamlit_extension.database import list_epics, list_tasks, get_connection
     from streamlit_extension.utils.security import (
         check_rate_limit,  # pode ser None em fallback
     )
     from streamlit_extension.utils.exception_handler import (
         handle_streamlit_exceptions,
         streamlit_error_boundary,
         safe_streamlit_operation,
         get_error_statistics,
     )
     DB_STACK_AVAILABLE = True
 except ImportError:
     load_config = DatabaseManager = None  # type: ignore
     handle_streamlit_exceptions = lambda **_: (  # type: ignore
         (lambda f: f) if STREAMLIT_AVAILABLE else (lambda f: f)
     )
     def streamlit_error_boundary(_name: str):  # type: ignore
         def _decorator(fn):
             def _inner(*a, **k):
                 return fn(*a, **k)
             return _inner
         return _decorator
     def safe_streamlit_operation(fn, *a, default_return=None, **k):  # type: ignore
         try:
             return fn(*a, **k)
         except Exception:
diff --git a/streamlit_extension/pages/settings.py b/streamlit_extension/pages/settings.py
index ef70c4ae2f7fc4b59c8de0fea374e8053c045f4f..d0878f3ad951487c632e48a22d299baae469091e 100644
--- a/streamlit_extension/pages/settings.py
+++ b/streamlit_extension/pages/settings.py
@@ -6,51 +6,51 @@ Configuration interface for the TDD Framework:
 - GitHub integration setup
 - Database configuration
 - Theme and UI preferences
 - Export/import settings
 """
 
 import sys
 from pathlib import Path
 from typing import Dict, Any, List, Optional
 import json
 from datetime import datetime
 
 # Add parent directory to path
 sys.path.append(str(Path(__file__).parent.parent.parent))
 
 # Graceful imports
 try:
     import streamlit as st
     STREAMLIT_AVAILABLE = True
 except ImportError:
     STREAMLIT_AVAILABLE = False
     st = None
 
 # Local imports
 try:
-    from streamlit_extension.utils.database import DatabaseManager
+    from streamlit_extension.database import list_epics, list_tasks, get_connection
     from streamlit_extension.config import load_config, create_streamlit_config_file
     from streamlit_extension.utils.security import (
         sanitize_display, validate_form, check_rate_limit,
         security_manager
     )
     from streamlit_extension.config.streamlit_config import reload_config
     DATABASE_UTILS_AVAILABLE = True
 except ImportError:
     DatabaseManager = load_config = create_streamlit_config_file = reload_config = None
     sanitize_display = validate_form = None
     check_rate_limit = security_manager = None
     DATABASE_UTILS_AVAILABLE = False
 
 # --- Autentica√ß√£o -------------------------------------------------------------
 # Import absoluto (corrige erro cr√≠tico do relat√≥rio):
 try:
     from streamlit_extension.auth.middleware import init_protected_page, require_auth
 except ImportError:
     # Fallback seguro em desenvolvimento: mant√©m p√°gina acess√≠vel
     def init_protected_page(title: str, *, layout: str = "wide") -> None:
         if STREAMLIT_AVAILABLE and st:
             st.set_page_config(page_title=title, layout=layout)
 
     def require_auth(role: Optional[str] = None):  # type: ignore
         def _decorator(fn):
diff --git a/usage_analysis.txt b/usage_analysis.txt
new file mode 100644
index 0000000000000000000000000000000000000000..0c72523fbcf4598a3e78f7d4ee12a6ce58b1d9aa
--- /dev/null
+++ b/usage_analysis.txt
@@ -0,0 +1,508 @@
+=== ANALYZING: streamlit_extension/integration/existing_system.py ===
+Import pattern:
+37:    from ..utils.database import DatabaseManager
+Usage patterns:
+37:    from ..utils.database import DatabaseManager
+40:    DatabaseManager = None
+80:        self.db_manager = DatabaseManager() if DATABASE_UTILS_AVAILABLE else None
+167:        existing_epics = self.db_manager.get_epics()
+222:            epics = self.db_manager.get_epics()
+228:                tasks = self.db_manager.get_tasks(epic_id=epic.get("id"))
+294:        user_stats = self.db_manager.get_user_stats()
+295:        timer_sessions = self.db_manager.get_timer_sessions(days)
+333:        epics = self.db_manager.get_epics()
+334:        all_tasks = self.db_manager.get_tasks()
+372:                db_health = self.db_manager.check_database_health()
+---
+=== ANALYZING: streamlit_extension/utils/redis_cache.py ===
+Import pattern:
+Usage patterns:
+17:- Integration with existing DatabaseManager
+---
+=== ANALYZING: streamlit_extension/utils/__init__.py ===
+Import pattern:
+3:from .database import DatabaseManager
+Usage patterns:
+3:from .database import DatabaseManager
+14:    "DatabaseManager",
+---
+=== ANALYZING: streamlit_extension/utils/cached_database.py ===
+Import pattern:
+62:    from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+4:Wrapper around existing DatabaseManager with intelligent Redis caching.
+13:- Transparent caching layer over existing DatabaseManager
+62:    from streamlit_extension.utils.database import DatabaseManager
+66:    DatabaseManager = None
+87:class CachedDatabaseManager:
+91:    Wraps existing DatabaseManager with transparent caching layer that:
+114:            raise ImportError("DatabaseManager not available")
+117:        self.db_manager = DatabaseManager(
+238:            result = self.db_manager.get_projects(
+263:            result = self.db_manager.get_project(project_id)
+279:            result = self.db_manager.create_project(**kwargs)
+294:            result = self.db_manager.update_project(project_id, **kwargs)
+309:            result = self.db_manager.delete_project(project_id, soft_delete=soft_delete)
+339:            result = self.db_manager.get_epics(
+365:            result = self.db_manager.get_epic(epic_id)
+395:            result = self.db_manager.get_tasks(
+422:            result = self.db_manager.get_task(task_id)
+529:        return self.db_manager.execute_query(query, params)
+533:        return self.db_manager.check_database_health()
+555:__all__ = ["CachedDatabaseManager"]
+---
+=== ANALYZING: streamlit_extension/utils/analytics_integration.py ===
+Import pattern:
+46:from .database import DatabaseManager
+47:from .cache import streamlit_cached, cache_database_query
+Usage patterns:
+46:from .database import DatabaseManager
+126:    def __init__(self, db_manager: DatabaseManager = None):
+152:        timer_sessions = self.db_manager.get_timer_sessions(days)
+182:                self.db_manager.logger.warning(f"Combined analytics query failed, falling back to separate queries: {e}")
+184:            timer_sessions = self.db_manager.get_timer_sessions(days)
+185:            tasks = self.db_manager.get_tasks()
+186:            epics = self.db_manager.get_epics()
+210:        week_sessions = self.db_manager.get_timer_sessions(7)
+236:        timer_sessions = self.db_manager.get_timer_sessions(days)
+276:                self.db_manager.logger.warning(f"Chart data optimization failed, using fallback: {e}")
+554:        all_sessions = self.db_manager.get_timer_sessions(1)
+572:        recent_sessions = self.db_manager.get_timer_sessions(1)  # Last day
+589:        recent_sessions = self.db_manager.get_timer_sessions(1)
+709:            raw_data = self.db_manager.execute_query(combined_query, (date_filter,))
+749:            user_stats_result = self.db_manager.execute_query(user_stats_query)
+761:                self.db_manager.logger.error(f"Database manager error in combined analytics query: {e}")
+765:                self.db_manager.logger.error(f"Unexpected error in combined analytics query: {e}")
+770:def create_analytics_engine(db_manager: DatabaseManager = None) -> StreamlitAnalyticsEngine:
+777:def get_productivity_summary(db_manager: DatabaseManager, days: int = 7) -> Dict[str, Any]:
+---
+=== ANALYZING: streamlit_extension/utils/database.py ===
+Import pattern:
+87:    from .cache import cache_database_query, invalidate_cache_on_change, get_cache
+Usage patterns:
+154:    """High-performance pagination methods for DatabaseManager."""
+486:class DatabaseManager(PerformancePaginationMixin):
+499:        >>> db = DatabaseManager()
+529:            >>> db_manager = DatabaseManager("/app/data/framework.db")
+530:            >>> db_manager = DatabaseManager("./framework.db", "./timer.db")
+589:            >>> db = DatabaseManager()
+625:            >>> conn = next(db_manager.get_connection())
+626:            >>> db_manager.release_connection(conn)
+1410:            >>> health = db_manager.check_database_health()
+1529:            >>> db_manager.clear_cache("db_query:get_projects:")
+1556:            >>> stats = db_manager.get_query_statistics()
+1580:            >>> report = db_manager.optimize_database()
+1607:            >>> backup_file = db_manager.create_backup()
+1626:            >>> db_manager.restore_backup("framework.bak")
+3201:        >>> with db_manager.get_connection() as conn:
+---
+=== ANALYZING: streamlit_extension/utils/app_setup.py ===
+Import pattern:
+44:    from ..database import get_connection, check_health  # type: ignore
+68:    from ..utils.database import DatabaseManager  # type: ignore
+416:        from streamlit_extension.database.queries import _DBM_INSTANCE as _Q_DBM  # type: ignore
+423:        from streamlit_extension.database.schema import _DBM_INSTANCE as _S_DBM  # type: ignore
+430:        from streamlit_extension.database.connection import _DBM_INSTANCE as _C_DBM  # type: ignore
+Usage patterns:
+14:- Legacy DatabaseManager for ServiceContainer initialization
+66:# Legacy DatabaseManager: used ONLY to compose ServiceContainer (until complete migration)
+68:    from ..utils.database import DatabaseManager  # type: ignore
+71:    DatabaseManager = None  # type: ignore
+146:_db_manager_singleton: Optional["DatabaseManager"] = None
+149:def get_database_manager(force_new: bool = False) -> Optional["DatabaseManager"]:
+151:    Returns (or creates) DatabaseManager legacy instance.
+156:    if DatabaseManager is None:
+157:        _logger.warning("Legacy DatabaseManager unavailable; services may not initialize.")
+163:                _db_manager_singleton = DatabaseManager()  # type: ignore[call-arg]
+164:                _logger.info("DatabaseManager (legacy) initialized.")
+166:                _logger.error("Failed to create DatabaseManager: %s", e, exc_info=True)
+170:def _create_service_container(dbm: Optional["DatabaseManager"]) -> Optional["ServiceContainer"]:
+355:            st.error("‚ùå Failed to initialize DatabaseManager (legacy).")
+367:def get_session_services() -> Tuple[Optional["DatabaseManager"], Optional["ServiceContainer"]]:
+369:    Returns (DatabaseManager legacy, ServiceContainer) from Streamlit session.
+---
+=== ANALYZING: streamlit_extension/utils/performance_tester.py ===
+Import pattern:
+573:    from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+189:                self.db_manager.create_project(
+197:                self.db_manager.get_projects(limit=10)
+225:                with self.db_manager.get_connection() as conn:
+542:        return db_manager.create_project(**data)
+563:        db_manager.get_projects(limit=10)
+573:    from streamlit_extension.utils.database import DatabaseManager
+575:    db_manager = DatabaseManager("framework.db", "task_timer.db")
+---
+=== ANALYZING: streamlit_extension/services/task_service.py ===
+Import pattern:
+17:from ..utils.database import DatabaseManager
+Usage patterns:
+17:from ..utils.database import DatabaseManager
+25:    def __init__(self, db_manager: DatabaseManager):
+39:            result = self.db_manager.execute_query(query, (task_id,))
+42:            self.db_manager.logger.error(f"Error finding task by ID {task_id}: {e}")
+49:            result = self.db_manager.execute_query(query, (task_key,))
+52:            self.db_manager.logger.error(f"Error finding task by key {task_key}: {e}")
+154:            total_count = self.db_manager.execute_query(count_query, params)[0]['COUNT(*)']
+163:            tasks = self.db_manager.execute_query(data_query, data_params)
+174:            self.db_manager.logger.error(f"Error finding tasks: {e}")
+191:            return self.db_manager.execute_query(query, (epic_id,))
+193:            self.db_manager.logger.error(f"Error finding tasks for epic {epic_id}: {e}")
+212:            return self.db_manager.execute_query(query, params)
+214:            self.db_manager.logger.error(f"Error finding tasks by status {status}: {e}")
+233:            return self.db_manager.execute_query(query, params)
+235:            self.db_manager.logger.error(f"Error finding tasks by TDD phase {tdd_phase}: {e}")
+264:            return self.db_manager.execute_insert(query, params)
+267:            self.db_manager.logger.error(f"Error creating task: {e}")
+298:            affected_rows = self.db_manager.execute_update(query, params)
+302:            self.db_manager.logger.error(f"Error updating task {task_id}: {e}")
+309:            self.db_manager.execute_update(
+---
+=== ANALYZING: streamlit_extension/services/service_container.py ===
+Import pattern:
+24:from ..utils.database import DatabaseManager  # type: ignore
+27:from ..database import connection as db_connection, queries as db_queries
+118:        from ..database.health import check_health  # type: ignore
+Usage patterns:
+5:Suporta API legada (DatabaseManager) e nova API modular via adapter.
+24:from ..utils.database import DatabaseManager  # type: ignore
+38:    Fornece uma interface semelhante ao DatabaseManager, usando a API modular.
+143:    Suporta API legada (DatabaseManager) ou a API modular (via adapter).
+146:    def __init__(self, db_manager: Optional[DatabaseManager] = None, use_modular_api: bool = False) -> None:
+149:            db_manager: Inst√¢ncia do DatabaseManager (obrigat√≥ria se use_modular_api=False)
+161:            "modular API" if use_modular_api else "legacy DatabaseManager",
+198:        Escopo transacional real: usa a transa√ß√£o da API modular ou do DatabaseManager.
+205:            cm = self.db_manager.transaction()
+332:def initialize_service_container(db_manager: DatabaseManager, lazy_loading: bool = True) -> ServiceContainer:
+418:    dm = DatabaseManager()  # type: ignore[call-arg]
+---
+=== ANALYZING: streamlit_extension/services/analytics_service.py ===
+Import pattern:
+20:from ..utils.database import DatabaseManager
+Usage patterns:
+20:from ..utils.database import DatabaseManager
+71:    def __init__(self, db_manager: DatabaseManager):
+110:            result = self.db_manager.execute_query(query, params)
+114:            self.db_manager.logger.error(f"Error getting project progress metrics: {e}")
+139:                self.db_manager.execute_query(phase_query, [date_filter])
+159:                self.db_manager.execute_query(cycle_query, [date_filter])
+170:            self.db_manager.logger.error(f"Error getting TDD cycle metrics: {e}")
+193:                self.db_manager.execute_query(daily_query, [date_filter])
+210:                self.db_manager.execute_query(focus_query, [date_filter])
+231:                self.db_manager.execute_query(accuracy_query, [date_filter])
+241:            self.db_manager.logger.error(f"Error getting productivity metrics: {e}")
+271:                self.db_manager.execute_query(epic_query, [date_filter])
+298:            self.db_manager.logger.error(f"Error getting gamification metrics: {e}")
+305:    def __init__(self, db_manager: DatabaseManager):
+---
+=== ANALYZING: streamlit_extension/services/project_service.py ===
+Import pattern:
+16:from ..utils.database import DatabaseManager
+Usage patterns:
+16:from ..utils.database import DatabaseManager
+41:    def __init__(self, db_manager: DatabaseManager):
+52:            result = self.db_manager.execute_query(query, (project_id,))
+55:            self.db_manager.logger.error(f"Error finding project by ID {project_id}: {e}")
+62:            result = self.db_manager.execute_query(query, (name,))
+65:            self.db_manager.logger.error(f"Error finding project by name {name}: {e}")
+131:            total_count = self.db_manager.execute_query(count_query, params)[0]['total']
+140:            projects = self.db_manager.execute_query(data_query, data_params)
+151:            self.db_manager.logger.error(f"Error finding projects: {e}")
+158:            return self.db_manager.execute_query(query)
+160:            self.db_manager.logger.error(f"Error finding projects: {e}")
+184:            return self.db_manager.execute_insert(query, params)
+187:            self.db_manager.logger.error(f"Error creating project: {e}")
+213:            affected_rows = self.db_manager.execute_update(query, params)
+217:            self.db_manager.logger.error(f"Error updating project {project_id}: {e}")
+230:            affected_rows = self.db_manager.execute_update(query, params)
+234:            self.db_manager.logger.error(f"Error deleting project {project_id}: {e}")
+241:            result = self.db_manager.execute_query(query, (project_id,))
+244:            self.db_manager.logger.error(f"Error counting epics for project {project_id}: {e}")
+257:            epic_counts = self.db_manager.execute_query(epic_query, (project_id,))
+---
+=== ANALYZING: streamlit_extension/services/epic_service.py ===
+Import pattern:
+17:from ..utils.database import DatabaseManager
+Usage patterns:
+17:from ..utils.database import DatabaseManager
+45:    def __init__(self, db_manager: DatabaseManager):
+57:            result = self.db_manager.execute_query(query, (epic_id,))
+60:            self.db_manager.logger.error(f"Error finding epic by ID {epic_id}: {e}")
+67:            result = self.db_manager.execute_query(query, (epic_key,))
+70:            self.db_manager.logger.error(f"Error finding epic by key {epic_key}: {e}")
+156:            total_count = self.db_manager.execute_query(count_query, params)[0]['COUNT(*)']
+165:            epics = self.db_manager.execute_query(data_query, data_params)
+184:            self.db_manager.logger.error(f"Error finding epics: {e}")
+199:            epics = self.db_manager.execute_query(query, (project_id,))
+211:            self.db_manager.logger.error(f"Error finding epics for project {project_id}: {e}")
+240:            return self.db_manager.execute_insert(query, params)
+243:            self.db_manager.logger.error(f"Error creating epic: {e}")
+274:            affected_rows = self.db_manager.execute_update(query, params)
+278:            self.db_manager.logger.error(f"Error updating epic {epic_id}: {e}")
+291:            affected_rows = self.db_manager.execute_update(query, params)
+295:            self.db_manager.logger.error(f"Error deleting epic {epic_id}: {e}")
+302:            result = self.db_manager.execute_query(query, (epic_id,))
+305:            self.db_manager.logger.error(f"Error counting tasks for epic {epic_id}: {e}")
+318:            task_counts = self.db_manager.execute_query(task_query, (epic_id,))
+---
+=== ANALYZING: streamlit_extension/services/timer_service.py ===
+Import pattern:
+17:from ..utils.database import DatabaseManager
+Usage patterns:
+17:from ..utils.database import DatabaseManager
+79:    def __init__(self, db_manager: DatabaseManager):
+118:            result = self.db_manager.execute_query(query, (session_id,))
+121:            self.db_manager.logger.error(f"Database manager error for session {session_id}: {e}")
+124:            self.db_manager.logger.error(f"Unexpected error finding session {session_id}: {e}")
+140:            result = self.db_manager.execute_query(query)
+143:            self.db_manager.logger.error(f"Database manager error finding active session: {e}")
+146:            self.db_manager.logger.error(f"Unexpected error finding active session: {e}")
+163:            return self.db_manager.execute_query(query, params)
+165:            self.db_manager.logger.error(f"Error finding sessions for task {task_id}: {e}")
+192:            return self.db_manager.execute_query(base_query, params)
+194:            self.db_manager.logger.error(f"Error finding sessions by date range: {e}")
+213:            return self.db_manager.execute_query(query, [date_filter, limit])
+215:            self.db_manager.logger.error(f"Error finding recent sessions: {e}")
+245:            return self.db_manager.execute_insert(query, params)
+248:            self.db_manager.logger.error(f"Error creating session: {e}")
+276:            affected_rows = self.db_manager.execute_update(query, params)
+280:            self.db_manager.logger.error(f"Error updating session {session_id}: {e}")
+287:            affected_rows = self.db_manager.execute_update(query, (session_id,))
+290:            self.db_manager.logger.error(f"Error deleting session {session_id}: {e}")
+---
+=== ANALYZING: streamlit_extension/models/base.py ===
+Import pattern:
+26:from .database import create_db_engine, get_database_url
+314:        from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+Usage patterns:
+138:        # Se n√£o informado, resolve via m√≥dulo central (framework.db / env / DatabaseManager)
+309:    Integra a URL do SQLAlchemy com o DatabaseManager existente, quando presente.
+314:        from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+316:        db_manager = DatabaseManager()
+317:        # Se o DatabaseManager exp√µe .db_path, resolvemos via camada central para n√£o errar o driver.
+318:        if hasattr(db_manager, "db_path") and db_manager.db_path:
+319:            database_url = get_database_url(str(db_manager.db_path))
+322:        logger.info("Integra√ß√£o com DatabaseManager conclu√≠da com sucesso.")
+324:        logger.info("DatabaseManager n√£o dispon√≠vel para integra√ß√£o.")
+326:        logger.warning(f"Falha na integra√ß√£o com DatabaseManager: {e}")
+---
+=== ANALYZING: streamlit_extension/models/database.py ===
+Import pattern:
+115:            from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+330:        from streamlit_extension.database.connection import (  # type: ignore
+340:        from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+Usage patterns:
+99:        Prioridade: par√¢metro ‚Üí env FRAMEWORK_DB ‚Üí DatabaseManager ‚Üí ./framework.db
+115:            from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+116:            db_manager = DatabaseManager()
+118:                return str(db_manager.db_path)
+120:            logger.info("DatabaseManager n√£o dispon√≠vel para integra√ß√£o")
+122:            logger.warning(f"N√£o foi poss√≠vel integrar com DatabaseManager: {e}")
+340:        from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+341:        _ = DatabaseManager
+342:        logger.info("Config sincroniz√°vel com DatabaseManager (se necess√°rio).")
+344:        logger.info("DatabaseManager indispon√≠vel para sync de configura√ß√£o.")
+---
+=== ANALYZING: streamlit_extension/pages/timer.py ===
+Import pattern:
+30:    from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+30:    from streamlit_extension.utils.database import DatabaseManager
+45:    DatabaseManager = load_config = TimerComponent = None
+83:        db_manager = DatabaseManager(
+198:def _render_main_timer(timer_component, db_manager: DatabaseManager, config):
+207:        tasks = db_manager.get_tasks()
+318:def _render_session_stats(db_manager: DatabaseManager):
+363:def _render_session_history(db_manager: DatabaseManager):
+371:        return db_manager.get_timer_sessions(days=7)
+435:def _render_tdah_insights(db_manager: DatabaseManager):
+443:        return db_manager.get_timer_sessions(days=14)
+508:def _start_timer_session(timer_component, db_manager: DatabaseManager):
+537:def _end_timer_session(timer_component, db_manager: DatabaseManager):
+562:def _skip_timer_session(timer_component, db_manager: DatabaseManager):
+609:def _get_todays_sessions(db_manager: DatabaseManager) -> List[Dict[str, Any]]:
+612:    all_sessions = db_manager.get_timer_sessions(days=1)
+---
+=== ANALYZING: streamlit_extension/pages/gantt.py ===
+Import pattern:
+51:    from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+51:    from streamlit_extension.utils.database import DatabaseManager
+63:    load_config = DatabaseManager = None  # type: ignore
+193:def _init_db() -> Optional[DatabaseManager]:  # type: ignore[name-defined]
+194:    """Inicializa DatabaseManager com assinatura alinhada ao Analytics."""
+201:            DatabaseManager,
+---
+=== ANALYZING: streamlit_extension/pages/kanban.py ===
+Import pattern:
+30:    from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+30:    from streamlit_extension.utils.database import DatabaseManager
+40:    DatabaseManager = load_config = security_manager = None
+112:            DatabaseManager,
+140:            db_manager.get_tasks,
+149:            db_manager.get_epics,
+181:def _render_sidebar_filters(db_manager: DatabaseManager):
+189:        return db_manager.get_epics()
+273:def _render_kanban_board(tasks: List[Dict[str, Any]], db_manager: DatabaseManager, epics: List[Dict[str, Any]]):
+323:def _render_task_card(task: Dict[str, Any], db_manager: DatabaseManager, epics: List[Dict[str, Any]], current_status: str):
+470:def _show_quick_add_modal(db_manager: DatabaseManager, epics: List[Dict[str, Any]]):
+555:def _render_create_task_form(db_manager: DatabaseManager, epics: List[Dict[str, Any]]):
+655:def _show_edit_task_modal(task: Dict[str, Any], db_manager: DatabaseManager, epics: List[Dict[str, Any]]):
+758:def _create_task(title: str, epic_id: Optional[int], tdd_phase: str, db_manager: DatabaseManager,
+762:        db_manager.create_task,
+775:def _update_task_status(task_id: int, new_status: str, db_manager: DatabaseManager) -> bool:
+778:        db_manager.update_task_status,
+787:                priority: int, estimate_minutes: int, db_manager: DatabaseManager) -> bool:
+790:        db_manager.update_task,
+802:def _delete_task(task_id: int, db_manager: DatabaseManager) -> bool:
+805:        db_manager.delete_task,
+---
+=== ANALYZING: streamlit_extension/pages/analytics.py ===
+Import pattern:
+72:    from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+72:    from streamlit_extension.utils.database import DatabaseManager
+83:    DatabaseManager = load_config = None  # type: ignore
+257:def optimize_database_queries(db_manager: "DatabaseManager", days: int, filters: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+274:                db_manager.get_timer_sessions(days)  # type: ignore[arg-type]
+288:            tasks = _ensure_dict_list(db_manager.get_tasks())
+289:            epics = _ensure_dict_list(db_manager.get_epics())
+302:            raw_stats = db_manager.get_user_stats()
+311:            "timer_sessions": _ensure_dict_list(db_manager.get_timer_sessions(days)),  # type: ignore[arg-type]
+312:            "tasks": _ensure_dict_list(db_manager.get_tasks()),
+313:            "epics": _ensure_dict_list(db_manager.get_epics()),
+314:            "user_stats": _normalize_user_stats(db_manager.get_user_stats()),
+390:        db_manager = DatabaseManager(
+410:def _render_analytics_filters(db_manager: "DatabaseManager") -> Dict[str, Any]:
+445:def _render_advanced_filters(db_manager: "DatabaseManager", days: int) -> Dict[str, Any]:
+451:            all_epics = db_manager.get_epics()
+522:def _fetch_analytics_data(db_manager: "DatabaseManager", analytics_engine: Any, filters: Dict[str, Any]) -> Dict[str, Any]:
+576:def _get_enhanced_analytics_data(analytics_engine: Any, db_manager: "DatabaseManager", days: int) -> Dict[str, Any]:
+597:def _get_analytics_data(db_manager: "DatabaseManager", days: int) -> Dict[str, Any]:
+---
+=== ANALYZING: streamlit_extension/pages/projects.py ===
+Import pattern:
+41:from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+41:from streamlit_extension.utils.database import DatabaseManager
+211:        db_manager = DatabaseManager(
+252:            projects_result = db_manager.get_projects(include_inactive=True)
+---
+=== ANALYZING: streamlit_extension/pages/projeto_wizard.py ===
+Import pattern:
+47:        from streamlit_extension.database import transaction  # type: ignore
+54:        from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+61:        from streamlit_extension.database import create_project as _cp  # type: ignore
+Usage patterns:
+8:# - Padr√£o h√≠brido de banco (DatabaseManager + transaction) com autodetec√ß√£o
+53:        # Enterprise API (DatabaseManager)
+54:        from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+55:        _DBM = DatabaseManager()
+71:    2) DatabaseManager().create_project()
+87:    # 2) DatabaseManager
+93:        return {"ok": False, "error": f"Falha ao criar projeto (DatabaseManager): {e}"}
+---
+=== ANALYZING: streamlit_extension/pages/settings.py ===
+Import pattern:
+31:    from streamlit_extension.utils.database import DatabaseManager
+Usage patterns:
+31:    from streamlit_extension.utils.database import DatabaseManager
+40:    DatabaseManager = load_config = create_streamlit_config_file = reload_config = None
+486:            DatabaseManager,
+495:            db_manager.check_database_health,
+---
+=== ANALYZING: streamlit_extension/database/__init__.py ===
+Import pattern:
+Usage patterns:
+3:Fase 1: apenas delega√ß√£o ao `DatabaseManager` existente.
+---
+=== ANALYZING: streamlit_extension/database/health.py ===
+Import pattern:
+11:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+14:# from streamlit_extension.database import connection as db_connection
+15:# from streamlit_extension.database.health import check_health as modular_check_health
+16:# from streamlit_extension.database import optimize as modular_optimize
+43:from .database_singleton import get_database_manager as _db
+62:        from streamlit_extension.database.health import check_health as modular_check_health  # type: ignore
+84:        from streamlit_extension.database import connection as db_connection  # type: ignore
+118:        from streamlit_extension.database import optimize as modular_optimize  # type: ignore
+125:        from streamlit_extension.database import connection as db_connection  # type: ignore
+172:        from streamlit_extension.database import connection as db_connection  # type: ignore
+202:        from streamlit_extension.database import connection as db_connection  # type: ignore
+Usage patterns:
+11:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+20:_DBM_INSTANCE: Optional[DatabaseManager] = None  # type: ignore
+25:# Singleton do DatabaseManager (com inje√ß√£o/reset para testes)
+27:def set_database_manager(dbm: Optional[DatabaseManager]) -> None:
+29:    Injeta uma inst√¢ncia de DatabaseManager (√∫til para testes) ou reseta quando None.
+34:        logger.debug("DatabaseManager singleton %s", "reset" if dbm is None else "injected")
+37:def get_database_manager() -> DatabaseManager:
+---
+=== ANALYZING: streamlit_extension/database/schema.py ===
+Import pattern:
+8:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+46:from .database_singleton import get_database_manager as _db
+75:        from streamlit_extension.database import create_schema_if_needed as modular_create  # type: ignore
+Usage patterns:
+8:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+12:_DBM_INSTANCE: Optional[DatabaseManager] = None  # type: ignore
+21:def set_database_manager(dbm: Optional[DatabaseManager]) -> None:
+23:    Injeta uma inst√¢ncia de ``DatabaseManager`` (√∫til para testes) ou reseta quando None.
+31:            logger.debug("Resetting DatabaseManager singleton to None")
+34:            if not isinstance(dbm, DatabaseManager):  # type: ignore[arg-type]
+35:                raise TypeError("dbm must be an instance of DatabaseManager")
+37:            logger.debug("Injected custom DatabaseManager singleton")
+40:def get_database_manager() -> DatabaseManager:
+41:    """Retorna a inst√¢ncia singleton atual do DatabaseManager (criando sob demanda)."""
+54:      1) Se o DatabaseManager legado exp√µe `create_schema_if_needed`, delega para ele.
+64:                logger.info("Creating/upgrading schema via legacy DatabaseManager...")
+68:                logger.info("Schema created/verified via legacy DatabaseManager.")
+88:        "No schema creation path succeeded. Ensure either the legacy DatabaseManager "
+---
+=== ANALYZING: streamlit_extension/database/seed.py ===
+Import pattern:
+5:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+23:from .database_singleton import get_database_manager as _db
+Usage patterns:
+5:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+7:_DBM_INSTANCE: DatabaseManager | None = None  # type: ignore
+15:def set_database_manager(dbm: DatabaseManager) -> None:
+16:    """Helper para injetar um ``DatabaseManager`` (ex.: testes/mocks)."""
+---
+=== ANALYZING: streamlit_extension/database/queries.py ===
+Import pattern:
+6:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+14:from .database_singleton import get_database_manager as _db
+Usage patterns:
+6:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+9:_DBM_INSTANCE: DatabaseManager | None = None  # type: ignore
+21:# Adapta√ß√£o compat√≠vel com a API legada (delega√ß√£o ao DatabaseManager)
+25:    """Lista epics conforme regra do DatabaseManager legado."""
+---
+=== ANALYZING: streamlit_extension/database/database_singleton.py ===
+Import pattern:
+19:from ..utils.database import DatabaseManager
+Usage patterns:
+4:Centralized DatabaseManager singleton to eliminate semantic duplication.
+18:# Import DatabaseManager
+19:from ..utils.database import DatabaseManager
+26:_DBM_INSTANCE: Optional[DatabaseManager] = None
+29:def get_database_manager() -> DatabaseManager:
+31:    Thread-safe singleton DatabaseManager (double-checked locking).
+36:        DatabaseManager: Singleton instance
+50:            _DBM_INSTANCE = DatabaseManager()
+---
+=== ANALYZING: streamlit_extension/database/connection.py ===
+Import pattern:
+13:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+83:from .database_singleton import get_database_manager as _db
+Usage patterns:
+12:# Ajuste o import conforme a localiza√ß√£o real do DatabaseManager
+13:from streamlit_extension.utils.database import DatabaseManager  # type: ignore
+22:_DBM_INSTANCE: Optional[DatabaseManager] = None  # type: ignore
+73:# DatabaseManager (Singleton Delegation)
+76:def set_database_manager(dbm: DatabaseManager) -> None:
+77:    """Permite injetar um ``DatabaseManager`` (ex.: testes)."""
+92:# def _db() -> DatabaseManager:
+---
 
EOF
)