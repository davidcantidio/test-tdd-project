 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/streamlit_extension/components/sidebar.py b/streamlit_extension/components/sidebar.py
index 95de49b89f4476037144d6ebd032d3c2e013f2dd..cfd211b3be88c6530f0f36c5df2e8d7d7efd3702 100644
--- a/streamlit_extension/components/sidebar.py
+++ b/streamlit_extension/components/sidebar.py
@@ -16,51 +16,51 @@ except ImportError:
 
 try:
     from ..config import get_config
 except ImportError:
     get_config = None
 
 # Import database utilities - migrated to modular API
 try:
     from ..database import get_connection, transaction
     from ..database.queries import list_epics, list_tasks, list_timer_sessions
     DATABASE_AVAILABLE = True
 except ImportError:
     try:
         from streamlit_extension.database import get_connection, transaction
         from streamlit_extension.database.queries import list_epics, list_tasks, list_timer_sessions
         DATABASE_AVAILABLE = True
     except ImportError:
         get_connection = None
         transaction = None
         list_epics = None
         list_tasks = None
         list_timer_sessions = None
         DATABASE_AVAILABLE = False
 
 
-def render_sidebar() -> Dict[str, Any]:
+def render_sidebar(user_id: int = 1) -> Dict[str, Any]:
     """
     Render the persistent sidebar with timer and navigation.
     
     Returns:
         Dict containing sidebar state and user actions
     """
     if not STREAMLIT_AVAILABLE:
         return {"error": "Streamlit not available"}
     
     sidebar_state = {}
     
     with st.sidebar:
         # Header
         st.markdown("# 🚀 TDD Framework")
         st.markdown("---")
         
         # Timer Section (placeholder for now)
         st.markdown("## ⏱️ Timer")
         
         # Initialize timer state
         if "timer_running" not in st.session_state:
             st.session_state.timer_running = False
             st.session_state.timer_start_time = None
             st.session_state.current_task = None
             st.session_state.elapsed_seconds = 0  # acumulado quando pausado
@@ -114,51 +114,51 @@ def render_sidebar() -> Dict[str, Any]:
         
         # Epic Progress Section (placeholder)
         st.markdown("## 📊 Current Epic")
         
         # Progress bar (placeholder)
         progress_value = 0.65  # 65% completion
         st.progress(progress_value)
         st.markdown(f"**Progress:** {int(progress_value * 100)}%")
         
         # Stats
         st.markdown("### 📈 Today's Stats")
         col1, col2 = st.columns(2)
         with col1:
             st.metric("Tasks Done", "3", "1")
         with col2:
             st.metric("Focus Time", "2.5h", "0.5h")
         
         st.markdown("---")
         
         # Gamification Section (real data)
         cfg = get_config() if get_config else None
         if cfg and getattr(cfg, "enable_gamification", False):
             st.markdown("## 🏆 Achievements")
             
             # Get real gamification data
-            gamification_data = _get_gamification_data()
+            gamification_data = _get_gamification_data(user_id)
             
             # Points display
             total_points = gamification_data.get("total_points", 0)
             recent_points = gamification_data.get("recent_points", 0)
             st.metric("🌟 Total Points", f"{total_points:,}", f"+{recent_points}" if recent_points > 0 else None)
             
             # Streak
             current_streak = gamification_data.get("current_streak", 0)
             streak_type = gamification_data.get("streak_type", "daily focus")
             st.metric("🔥 Current Streak", f"{current_streak} days", f"{streak_type}")
             
             # Recent achievements
             achievements = gamification_data.get("recent_achievements", [])
             if achievements:
                 st.markdown("### 🏅 Recent Badges")
                 for achievement in achievements[:3]:  # Show last 3
                     badge_emoji = _get_achievement_emoji(achievement.get("code", ""))
                     st.markdown(f"{badge_emoji} **{achievement.get('name', 'Achievement')}** - {achievement.get('description', '')}")
             else:
                 st.markdown("### 🏅 Keep working to unlock badges!")
             
             # Progress to next achievement
             next_achievement = _get_next_achievement_progress(gamification_data)
             if next_achievement:
                 st.markdown("### 🎯 Next Goal")
@@ -197,63 +197,63 @@ def render_sidebar() -> Dict[str, Any]:
     
     return sidebar_state
 
 
 def render_timer_controls() -> Dict[str, Any]:
     """
     Render just the timer controls (for embedding in other components).
     
     Returns:
         Dict containing timer state
     """
     if not STREAMLIT_AVAILABLE:
         return {"error": "Streamlit not available"}
     
     # This would be a more focused timer component
     # Implementation would be similar to the sidebar version
     # but optimized for embedding in other pages
     
     return {
         "timer_running": False,
         "elapsed_time": "00:00",
         "current_task": None
     }
 
 
-def _get_gamification_data() -> Dict[str, Any]:
+def _get_gamification_data(user_id: int = 1) -> Dict[str, Any]:
     """Get real gamification data from database."""
     if not DATABASE_AVAILABLE:
         return _get_fallback_gamification_data()
-    
+
     try:
         if DATABASE_AVAILABLE:
             # Get user stats (points, completed tasks)
             from ..database.queries import get_user_stats, get_achievements
-            user_stats = get_user_stats()
-            
+            user_stats = get_user_stats(user_id)
+
             # Get achievements
-            achievements = get_achievements()
+            achievements = get_achievements(user_id)
         
         # Get timer sessions for streak calculation
         timer_sessions = list_timer_sessions(days=30) if list_timer_sessions else []
         
         # Calculate streaks
         current_streak, streak_type = _calculate_streaks(timer_sessions)
         
         # Calculate recent points (last 7 days)
         recent_points = _calculate_recent_points(timer_sessions, achievements)
         
         return {
             "total_points": user_stats.get("total_points", 0),
             "recent_points": recent_points,
             "current_streak": current_streak,
             "streak_type": streak_type,
             "recent_achievements": achievements[:5],  # Last 5 achievements
             "completed_tasks": user_stats.get("completed_tasks", 0),
             "active_streaks": user_stats.get("active_streaks", 0)
         }
         
     except Exception as e:
         print(f"Error loading gamification data: {e}")
         return _get_fallback_gamification_data()
 
 
diff --git a/streamlit_extension/database/connection.py b/streamlit_extension/database/connection.py
index a4327f6c72a49a26c7f6ba793b6a89ad4cda6647..5539e1f225e141476c0ca67eafaaa1c38d344f5c 100644
--- a/streamlit_extension/database/connection.py
+++ b/streamlit_extension/database/connection.py
@@ -1,49 +1,57 @@
 from __future__ import annotations
 
+import threading
 from contextlib import contextmanager
 from typing import Any, Iterable, Iterator, Optional
 
 # Ajuste o import conforme a localização real do DatabaseManager
 from streamlit_extension.utils.database import DatabaseManager  # type: ignore
 
 _DBM_INSTANCE: DatabaseManager | None = None  # type: ignore
+_DBM_LOCK = threading.Lock()
 
 
 def set_database_manager(dbm: DatabaseManager) -> None:
     """Permite injetar um ``DatabaseManager`` (ex.: testes)."""
 
     global _DBM_INSTANCE
     _DBM_INSTANCE = dbm  # type: ignore
 
 
 def _db() -> DatabaseManager:
-    global _DBM_INSTANCE  # type: ignore
-    try:
-        return _DBM_INSTANCE  # type: ignore
-    except NameError:
-        _DBM_INSTANCE = DatabaseManager()  # type: ignore
+    """
+    Thread-safe singleton pattern para DatabaseManager.
+    Usa double-checked locking para performance.
+    """
+    global _DBM_INSTANCE
+    if _DBM_INSTANCE is not None:
+        return _DBM_INSTANCE
+
+    with _DBM_LOCK:
+        if _DBM_INSTANCE is None:
+            _DBM_INSTANCE = DatabaseManager()
         return _DBM_INSTANCE
 
 
 def get_connection():
     """Obtém uma conexão do manager atual."""
 
     return _db().get_connection()
 
 
 def release_connection(conn) -> None:
     """Libera uma conexão obtida via ``get_connection()``."""
 
     return _db().release_connection(conn)
 
 
 @contextmanager
 def transaction() -> Iterator[Any]:
     """Delegação de transação para o manager atual."""
 
     with _db().transaction() as tx:
         yield tx
 
 
 def execute(sql: str, params: Optional[Iterable[Any]] = None) -> Any:
     """Execução genérica de SQL, delegada ao manager."""
diff --git a/streamlit_extension/database/health.py b/streamlit_extension/database/health.py
index 1c31154013ac185e50104396461ef998798a1bc0..ea92d92b157b32b0771239efcd8e2c82dd65583c 100644
--- a/streamlit_extension/database/health.py
+++ b/streamlit_extension/database/health.py
@@ -1,41 +1,49 @@
 from __future__ import annotations
 
+import threading
 from pathlib import Path
 from typing import Any, Dict
 
 from streamlit_extension.utils.database import DatabaseManager  # type: ignore
 
 _DBM_INSTANCE: DatabaseManager | None = None  # type: ignore
+_DBM_LOCK = threading.Lock()
 
 
 def _db() -> DatabaseManager:
-    global _DBM_INSTANCE  # type: ignore
-    try:
-        return _DBM_INSTANCE  # type: ignore
-    except NameError:
-        _DBM_INSTANCE = DatabaseManager()  # type: ignore
+    """
+    Thread-safe singleton pattern para DatabaseManager.
+    Usa double-checked locking para performance.
+    """
+    global _DBM_INSTANCE
+    if _DBM_INSTANCE is not None:
+        return _DBM_INSTANCE
+
+    with _DBM_LOCK:
+        if _DBM_INSTANCE is None:
+            _DBM_INSTANCE = DatabaseManager()
         return _DBM_INSTANCE
 
 
 def check_health() -> Dict[str, Any]:
     """Health-check do banco via manager."""
 
     return _db().check_database_health()
 
 
 def get_query_stats() -> Dict[str, Any]:
     """Estatísticas de queries conforme implementado no manager."""
 
     return _db().get_query_statistics()
 
 
 def optimize() -> Dict[str, Any]:
     """Executa rotinas de otimização do banco (VACUUM/ANALYZE/etc.)."""
 
     return _db().optimize_database()
 
 
 def create_backup(path: str) -> str:
     """Cria backup no caminho informado. Garante diretório existente."""
 
     p = Path(path)
diff --git a/streamlit_extension/database/queries.py b/streamlit_extension/database/queries.py
index e948b402a20ea2e2106b91686e6dd415f19b3982..4b0c5702b0166c955910c4b189d0efb54958fc5f 100644
--- a/streamlit_extension/database/queries.py
+++ b/streamlit_extension/database/queries.py
@@ -1,40 +1,48 @@
 from __future__ import annotations
 
+import threading
 from typing import Any, Dict, List
 
 from streamlit_extension.utils.database import DatabaseManager  # type: ignore
 
 _DBM_INSTANCE: DatabaseManager | None = None  # type: ignore
+_DBM_LOCK = threading.Lock()
 
 
 def _db() -> DatabaseManager:
-    global _DBM_INSTANCE  # type: ignore
-    try:
-        return _DBM_INSTANCE  # type: ignore
-    except NameError:
-        _DBM_INSTANCE = DatabaseManager()  # type: ignore
+    """
+    Thread-safe singleton pattern para DatabaseManager.
+    Usa double-checked locking para performance.
+    """
+    global _DBM_INSTANCE
+    if _DBM_INSTANCE is not None:
+        return _DBM_INSTANCE
+
+    with _DBM_LOCK:
+        if _DBM_INSTANCE is None:
+            _DBM_INSTANCE = DatabaseManager()
         return _DBM_INSTANCE
 
 
 def list_epics() -> List[Dict[str, Any]]:
     """Lista epics ativos conforme regra do ``DatabaseManager``."""
 
     return _db().get_epics()
 
 
 def list_all_epics() -> List[Dict[str, Any]]:
     """Lista epics, incluindo arquivados/deletados (se suportado)."""
 
     return _db().get_all_epics()
 
 
 def list_tasks(epic_id: int) -> List[Dict[str, Any]]:
     """Lista tasks de um epic específico."""
 
     return _db().get_tasks(epic_id)
 
 
 def list_all_tasks() -> List[Dict[str, Any]]:
     """Lista todas as tasks; pode ser custoso."""
 
     return _db().get_all_tasks()
diff --git a/streamlit_extension/database/schema.py b/streamlit_extension/database/schema.py
index 548c4d92c63a77d84a3217a35532228a01b2faa8..8a8103a374651282420fc847ac48e4bb39ed0951 100644
--- a/streamlit_extension/database/schema.py
+++ b/streamlit_extension/database/schema.py
@@ -1,33 +1,41 @@
 from __future__ import annotations
 
+import threading
 from streamlit_extension.utils.database import DatabaseManager  # type: ignore
 
 _DBM_INSTANCE: DatabaseManager | None = None  # type: ignore
+_DBM_LOCK = threading.Lock()
 
 
 def set_database_manager(dbm: DatabaseManager) -> None:
     """Permite injetar um ``DatabaseManager`` (ex.: testes)."""
 
     global _DBM_INSTANCE
     _DBM_INSTANCE = dbm  # type: ignore
 
 
 def _db() -> DatabaseManager:
-    global _DBM_INSTANCE  # type: ignore
-    try:
-        return _DBM_INSTANCE  # type: ignore
-    except NameError:
-        _DBM_INSTANCE = DatabaseManager()  # type: ignore
+    """
+    Thread-safe singleton pattern para DatabaseManager.
+    Usa double-checked locking para performance.
+    """
+    global _DBM_INSTANCE
+    if _DBM_INSTANCE is not None:
+        return _DBM_INSTANCE
+
+    with _DBM_LOCK:
+        if _DBM_INSTANCE is None:
+            _DBM_INSTANCE = DatabaseManager()
         return _DBM_INSTANCE
 
 
 def create_schema_if_needed(verbose: bool = False) -> None:
     """
     Ponto central de DDL.
     Fase 1: delega para o manager (se existir).
     """
 
     db = _db()
     if hasattr(db, "create_schema_if_needed"):
         db.create_schema_if_needed(verbose=verbose)  # type: ignore[attr-defined]
 
diff --git a/streamlit_extension/services/service_container.py b/streamlit_extension/services/service_container.py
index 9f70cb38f09bb44c741582171bef77a929b33b97..fe1509a3e4053d00bbc5cb62cedf8220700cd57a 100644
--- a/streamlit_extension/services/service_container.py
+++ b/streamlit_extension/services/service_container.py
@@ -1,34 +1,35 @@
 """
 🏗️ Service Container
 
 Dependency injection container for managing service instances.
 Provides centralized service creation and lifecycle management.
 """
 
 from typing import Dict, Any, Optional, Type, TypeVar
 import logging
+import threading
 from contextlib import contextmanager
 from datetime import datetime
 
 from .base import BaseService
 from .client_service import ClientService
 from .project_service import ProjectService
 from .epic_service import EpicService
 from .task_service import TaskService
 from .analytics_service import AnalyticsService
 from .timer_service import TimerService
 from ..utils.database import DatabaseManager
 
 # Type variable for service types
 T = TypeVar('T', bound=BaseService)
 
 
 class ServiceError(Exception):
     """Exception raised by service container operations."""
     pass
 
 
 class ServiceContainer:
     """
     Dependency injection container for managing service instances.
     
@@ -38,50 +39,51 @@ class ServiceContainer:
     
     def __init__(self, db_manager: DatabaseManager):
         """
         Initialize service container.
         
         Args:
             db_manager: Database manager instance to inject into services
         """
         self.db_manager = db_manager
         self.logger = logging.getLogger(__name__)
         
         # Service registry
         self._services: Dict[str, BaseService] = {}
         self._service_classes: Dict[str, Type[BaseService]] = {
             'client': ClientService,
             'project': ProjectService,
             'epic': EpicService,
             'task': TaskService,
             'analytics': AnalyticsService,
             'timer': TimerService,
         }
         
         # Configuration
         self._lazy_loading = True
         self._initialized = False
+        self._lock = threading.Lock()
     
     def initialize(self, lazy_loading: bool = True) -> None:
         """
         Initialize the service container.
         
         Args:
             lazy_loading: If True, services are created on-demand. 
                          If False, all services are created immediately.
         """
         self._lazy_loading = lazy_loading
         
         if not lazy_loading:
             # Eagerly initialize all services
             for service_name in self._service_classes.keys():
                 self._create_service(service_name)
         
         self._initialized = True
         self.logger.info(f"Service container initialized (lazy_loading={lazy_loading})")
     
     def get_client_service(self) -> ClientService:
         """Get the client service instance."""
         return self._get_service('client', ClientService)
     
     def get_project_service(self) -> ProjectService:
         """Get the project service instance."""
@@ -239,66 +241,67 @@ class ServiceContainer:
         Get status information about the service container.
         
         Returns:
             Dictionary with container status information
         """
         return {
             'initialized': self._initialized,
             'lazy_loading': self._lazy_loading,
             'registered_services': list(self._service_classes.keys()),
             'created_services': list(self._services.keys()),
             'service_count': len(self._service_classes),
             'created_count': len(self._services)
         }
     
     def _get_service(self, service_name: str, service_class: Type[T]) -> T:
         """
         Get or create a service instance.
         
         Args:
             service_name: Name of the service
             service_class: Expected service class type
             
         Returns:
             Service instance
         """
-        if service_name not in self._services:
-            if not self._initialized:
-                raise ServiceError("Service container not initialized. Call initialize() first.")
-            
-            self._services[service_name] = self._create_service(service_name)
-        
-        service = self._services[service_name]
-        
-        # Type check for safety
-        if not isinstance(service, service_class):
-            raise ServiceError(
-                f"Service type mismatch: expected {service_class.__name__}, "
-                f"got {type(service).__name__}"
-            )
-        
-        return service
+        with self._lock:
+            if service_name not in self._services:
+                if not self._initialized:
+                    raise ServiceError("Service container not initialized. Call initialize() first.")
+
+                self._services[service_name] = self._create_service(service_name)
+
+            service = self._services[service_name]
+
+            # Type check for safety
+            if not isinstance(service, service_class):
+                raise ServiceError(
+                    f"Service type mismatch: expected {service_class.__name__}, "
+                    f"got {type(service).__name__}"
+                )
+
+            return service
     
     def _create_service(self, service_name: str, validate_only: bool = False) -> BaseService:
         """
         Create a new service instance.
         
         Args:
             service_name: Name of the service to create
             validate_only: If True, don't store the service instance
             
         Returns:
             New service instance
             
         Raises:
             ServiceError: If service cannot be created
         """
         if service_name not in self._service_classes:
             raise ServiceError(f"Unknown service: {service_name}")
         
         service_class = self._service_classes[service_name]
         
         try:
             # Create service with database manager dependency
             service = service_class(self.db_manager)
             
             if not validate_only:
diff --git a/streamlit_extension/utils/app_setup.py b/streamlit_extension/utils/app_setup.py
index 3307a6d49bb9e4290043260cc73ae0f25b5036f9..b4b83767d369b06b1c0b26eb93dc1b6ee7578d91 100644
--- a/streamlit_extension/utils/app_setup.py
+++ b/streamlit_extension/utils/app_setup.py
@@ -1,43 +1,44 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """
 🚀 Application Setup Utilities
 
 Centraliza setup/boot do app Streamlit:
 - Inicialização do container de serviços
 - Checagem/saúde do banco (API modular)
 - Estado de sessão Streamlit (quando disponível)
 - Limpeza controlada de recursos
 
 Compatível com:
 - API modular de banco (streamlit_extension.database.*)
 - DatabaseManager legado (streamlit_extension.utils.database.DatabaseManager) para o ServiceContainer
 """
 
 from __future__ import annotations
 
+import atexit
 import logging
 from dataclasses import dataclass
 from pathlib import Path
 from typing import Any, Callable, Dict, Optional, Tuple, TypeVar
 from threading import Lock
 
 # Streamlit (opcional)
 try:
     import streamlit as st
     STREAMLIT_AVAILABLE = True
 except Exception:
     st = None  # type: ignore
     STREAMLIT_AVAILABLE = False
 
 # Banco (API modular)
 # Mantém o consumo da API modular criada no refactor (get_connection, transaction, check_health)
 from ..database import get_connection, transaction, check_health  # type: ignore
 
 # Services
 from ..services import (  # type: ignore
     ServiceContainer,
     initialize_service_container,
     shutdown_service_container,
     ServiceError,
 )
@@ -296,50 +297,84 @@ def get_session_services() -> Tuple[Optional["DatabaseManager"], Optional["Servi
 def cleanup_application() -> None:
     """
     Libera recursos do app. Chamar no shutdown.
     - Encerra ServiceContainer
     - Solta referências a singletons
     - Limpa session_state (se existir)
     """
     global _service_container_singleton, _db_manager_singleton
 
     try:
         if _service_container_singleton:
             shutdown_service_container()
             _service_container_singleton = None
 
         _db_manager_singleton = None  # se precisar, feche conexões no DatabaseManager ao migrar
 
         if _is_streamlit() and hasattr(st, "session_state"):
             for key in ("db_manager", "service_container", "services_initialized"):
                 if key in st.session_state:
                     del st.session_state[key]
 
         _logger.info("Cleanup concluído.")
     except Exception as e:  # pragma: no cover
         _logger.error("Erro no cleanup: %s", e, exc_info=True)
 
+
+def cleanup_resources() -> None:
+    """Limpa recursos ao encerrar a aplicação."""
+    try:
+        closed_any = False
+        try:
+            from streamlit_extension.database.queries import _DBM_INSTANCE as _Q_DBM  # type: ignore
+            if _Q_DBM is not None and hasattr(_Q_DBM, "close"):
+                _Q_DBM.close()
+                closed_any = True
+        except Exception:
+            pass
+        try:
+            from streamlit_extension.database.schema import _DBM_INSTANCE as _S_DBM  # type: ignore
+            if _S_DBM is not None and hasattr(_S_DBM, "close"):
+                _S_DBM.close()
+                closed_any = True
+        except Exception:
+            pass
+        try:
+            from streamlit_extension.database.connection import _DBM_INSTANCE as _C_DBM  # type: ignore
+            if _C_DBM is not None and hasattr(_C_DBM, "close"):
+                _C_DBM.close()
+                closed_any = True
+        except Exception:
+            pass
+        if closed_any:
+            _logger.info("Database resources cleaned up")
+    except Exception as e:
+        _logger.error(f"Error during cleanup: {e}")
+
+
+atexit.register(cleanup_resources)
+
 # --------------------------------------------------------------------------------------
 # Setup “one-shot” do app
 # --------------------------------------------------------------------------------------
 def setup_application() -> None:
     """
     Ponto único de setup para a aplicação Streamlit.
     - Inicializa sessão/serviços
     - Exibe status de saúde
     """
     if not _is_streamlit():
         _logger.warning("Streamlit indisponível - setup de UI ignorado.")
         return
 
     try:
         initialize_streamlit_session()
         health = check_services_health()
 
         if not health.get("overall", {}).get("healthy", False):
             st.error("⚠️ Serviços não estão totalmente operacionais.")
             with st.expander("🔍 Detalhes de Saúde", expanded=False):
                 st.json(health)
         else:
             _logger.info("Setup da aplicação concluído com sucesso.")
     except Exception as e:  # pragma: no cover
         _logger.error("Application setup failed: %s", e, exc_info=True)
diff --git a/streamlit_extension/utils/database.py b/streamlit_extension/utils/database.py
index 52d28147ddfd1705b88a50e332d6ed4f99a71d67..c55a79ebb54c85fb7d0b9a4fd2a9febd9ef174b1 100644
--- a/streamlit_extension/utils/database.py
+++ b/streamlit_extension/utils/database.py
@@ -3538,61 +3538,80 @@ class DatabaseManager(PerformancePaginationMixin):
                     else:
                         cursor = conn.cursor()
                         cursor.execute("""
                             UPDATE {TableNames.PROJECTS}
                             SET deleted_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP
                             WHERE id = ?
                         """, (project_id,))
                         conn.commit()
                 else:
                     # Use transaction-wrapped cascade delete for hard deletes
                     # This prevents table locks during cascade operations  
                     return self.delete_cascade_safe(
                         table_name="projects",
                         record_id=project_id,
                         cascade_tables=["epics", "tasks"]  # Delete dependent records first
                     )
                 
                 return True
                 
         except Exception as e:
             logger.error(f"Error deleting project: {e}")
             if STREAMLIT_AVAILABLE and st:
                 st.error(f"❌ Error deleting project: {e}")
             return False
 
+    def close(self) -> None:
+        """
+        Fecha conexões e libera recursos do banco de dados.
+        Importante para cleanup adequado em testes e shutdown.
+        """
+        try:
+            if hasattr(self, 'engine'):
+                self.engine.dispose()
+                logger.info("Database engine disposed successfully")
+            if hasattr(self, 'timer_engine') and getattr(self, 'timer_engine'):
+                try:
+                    self.timer_engine.dispose()
+                    logger.info("Timer database engine disposed successfully")
+                except Exception as te:
+                    logger.warning(f"Error closing timer engine: {te}")
+        except Exception as e:
+            logger.error(f"Error closing database: {e}")
+            # Não re-raise para permitir cleanup gracioso
+
 
 # =============================================================================
 # 🔧 CONTEXT MANAGERS - Utility context managers for database operations
 # =============================================================================
 
 @contextmanager
 def dict_rows(connection: SQLiteConnection) -> Iterator[None]:
     """
     Context manager to temporarily set SQLite connection to return dict-like rows.
     
     This utility allows repository code to work with SQLite rows as dictionaries,
     making it easier to extract values safely and convert to dataclass objects.
     
     Args:
         connection: SQLite connection object
         
     Yields:
         None (modifies connection row_factory temporarily)
         
     Example:
         >>> with db_manager.get_connection() as conn:
         ...     with dict_rows(conn):
         ...         rows = conn.execute("SELECT * FROM tasks").fetchall()
         ...         for row in rows:
         ...             task_key = row.get('task_key', 'unknown')  # Safe access
     """
     # Store original row factory
     original_row_factory = connection.row_factory
     
     try:
         # Set row factory to return sqlite3.Row objects (dict-like)
         connection.row_factory = sqlite3.Row
         yield
     finally:
         # Restore original row factory
-        connection.row_factory = original_row_factory
\ No newline at end of file
+        connection.row_factory = original_row_factory
diff --git a/streamlit_extension/utils/exception_handler.py b/streamlit_extension/utils/exception_handler.py
index 2d94c701569b23bfdd2d625e1c95155e5ea60612..3160d54c3274c1777ba3077f013caddf827b0772 100644
--- a/streamlit_extension/utils/exception_handler.py
+++ b/streamlit_extension/utils/exception_handler.py
@@ -1,47 +1,48 @@
 """
 🛡️ Global Exception Handler for Streamlit Applications
 
 Comprehensive exception handling system that prevents raw error messages from reaching the UI
 and provides structured error logging with security considerations.
 
 Features:
 - Global exception catching for all Streamlit operations
 - Sanitized error messages for users
 - Comprehensive error logging for developers
 - Security-aware error handling (no sensitive data leakage)
 - Integration with existing security framework
 - Production-ready error recovery
 """
 
 import sys
 import time
 import traceback
 import functools
 import threading
+from collections import deque
 from pathlib import Path
-from typing import Any, Callable, Dict, List, Optional, Tuple, Union
+from typing import Any, Callable, Deque, Dict, List, Optional, Tuple, Union
 from datetime import datetime
 from contextlib import contextmanager
 
 # Add duration_system to path for security module
 sys.path.append(str(Path(__file__).parent.parent.parent / "duration_system"))
 
 try:
     import streamlit as st
     STREAMLIT_AVAILABLE = True
 except ImportError:
     STREAMLIT_AVAILABLE = False
     
     # Mock streamlit for testing
     class MockStreamlit:
         def __getattr__(self, name):
             def mock_func(*args, **kwargs):
                 return None
             return mock_func
     st = MockStreamlit()
 
 try:
     from log_sanitization import create_secure_logger, sanitize_log_message, sanitize_exception
     LOG_SANITIZATION_AVAILABLE = True
 except ImportError:
     LOG_SANITIZATION_AVAILABLE = False
@@ -157,51 +158,51 @@ class GlobalExceptionHandler:
     
     def __init__(self):
         """Initialize the global exception handler."""
         # Initialize secure logging
         if LOG_SANITIZATION_AVAILABLE:
             self.logger = create_secure_logger('streamlit_exceptions')
         else:
             import logging
             self.logger = logging.getLogger('streamlit_exceptions')
             self.logger.setLevel(logging.ERROR)
             
             # Create console handler if none exists
             if not self.logger.handlers:
                 handler = logging.StreamHandler()
                 formatter = logging.Formatter(
                     '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                 )
                 handler.setFormatter(formatter)
                 self.logger.addHandler(handler)
         
         # Error statistics
         self.error_stats = {
             "total_errors": 0,
             "errors_by_category": {},
             "errors_by_severity": {},
-            "recent_errors": [],
+            "recent_errors": deque(maxlen=100),
             "last_reset": time.time()
         }
         
         # Error recovery strategies
         self.recovery_strategies = {}
         self._setup_default_recovery_strategies()
         
         # Thread lock for stats
         self._stats_lock = threading.Lock()
         
     def _setup_default_recovery_strategies(self):
         """Setup default error recovery strategies."""
         self.recovery_strategies = {
             ErrorCategory.DATABASE: self._recover_database_error,
             ErrorCategory.AUTHENTICATION: self._recover_auth_error,
             ErrorCategory.VALIDATION: self._recover_validation_error,
             ErrorCategory.NETWORK: self._recover_network_error,
             ErrorCategory.FILE_SYSTEM: self._recover_filesystem_error,
             ErrorCategory.SECURITY: self._recover_security_error,
             ErrorCategory.USER_INPUT: self._recover_user_input_error,
             ErrorCategory.BUSINESS_LOGIC: self._recover_business_logic_error,
             ErrorCategory.SYSTEM: self._recover_system_error
         }
     
     def classify_exception(self, exception: Exception, context: Optional[Dict[str, Any]] = None) -> Tuple[str, str]:
@@ -312,63 +313,59 @@ class GlobalExceptionHandler:
             
             return error
             
         except Exception as e:
             # Fallback error handling to prevent recursive errors
             self.logger.error(f"Exception in exception handler: {e}")
             if STREAMLIT_AVAILABLE:
                 st.error("🚨 A critical error occurred. Please refresh the page.")
             
             # Return minimal error object
             return StreamlitError(exception=exception)
     
     def _update_error_stats(self, error: StreamlitError):
         """Update error statistics."""
         with self._stats_lock:
             self.error_stats["total_errors"] += 1
             
             # Update category stats
             category_stats = self.error_stats["errors_by_category"]
             category_stats[error.category] = category_stats.get(error.category, 0) + 1
             
             # Update severity stats
             severity_stats = self.error_stats["errors_by_severity"]
             severity_stats[error.severity] = severity_stats.get(error.severity, 0) + 1
             
-            # Add to recent errors (keep last 10)
-            recent = self.error_stats["recent_errors"]
+            # Add to recent errors (deque handles max size)
+            recent: Deque[Dict[str, Any]] = self.error_stats["recent_errors"]
             recent.append({
                 "error_id": error.error_id,
                 "category": error.category,
                 "severity": error.severity,
                 "timestamp": error.timestamp.isoformat(),
                 "message": str(error.exception)[:100]
             })
-            
-            # Keep only last 10 errors
-            if len(recent) > 10:
-                recent.pop(0)
     
     def _log_error(self, error: StreamlitError):
         """Log error with appropriate level."""
         safe_context = error.get_safe_context()
         
         # Create log message
         log_data = {
             "error_id": error.error_id,
             "category": error.category,
             "severity": error.severity,
             "exception_type": type(error.exception).__name__,
             "message": str(error.exception)[:500],  # Truncate long messages
             "context": safe_context
         }
         
         # Log with appropriate level based on severity
         if error.severity == ErrorSeverity.CRITICAL:
             if LOG_SANITIZATION_AVAILABLE:
                 self.logger.critical(sanitize_log_message(f"Critical error: {log_data}", 'CRITICAL'))
             else:
                 self.logger.critical(f"Critical error: {log_data}")
         elif error.severity == ErrorSeverity.HIGH:
             if LOG_SANITIZATION_AVAILABLE:
                 self.logger.error(sanitize_log_message(f"High severity error: {log_data}", 'ERROR'))
             else:
diff --git a/streamlit_extension/utils/security.py b/streamlit_extension/utils/security.py
index f2dceda9f102f859e695beefe3bacd7ea97a962c..07d42c5bbb232f3bae8a7f4036d4b26f0f388f60 100644
--- a/streamlit_extension/utils/security.py
+++ b/streamlit_extension/utils/security.py
@@ -430,64 +430,64 @@ class StreamlitSecurityManager:
         try:
             return self.rate_limiter.get_stats()
         except Exception as e:
             return {"error": str(e)}
     
     def reset_rate_limits(self, 
                          operation_type: str,
                          user_id: Optional[str] = None,
                          ip_address: Optional[str] = None):
         """Reset rate limits for specific user/operation."""
         if not RATE_LIMITING_AVAILABLE or not self.rate_limiter:
             return
         
         try:
             self.rate_limiter.reset_entity(
                 limit_type=operation_type,
                 user_id=user_id,
                 ip_address=ip_address
             )
         except Exception as e:
             if LOG_SANITIZATION_AVAILABLE:
                 self.logger.error(sanitize_log_message(f"Failed to reset rate limits: {e}", 'ERROR'))
             else:
                 self.logger.error(f"Failed to reset rate limits: {str(e)[:100]}")
     
-    def _get_streamlit_session_id(self) -> Optional[str]:
-        """Extract session ID from Streamlit context."""
+    def _get_streamlit_session_id(self) -> str:
+        """Obtém ID único da sessão Streamlit de forma segura."""
         try:
             import streamlit as st
             if hasattr(st, 'session_state') and hasattr(st.session_state, 'session_id'):
-                return st.session_state.session_id
-            # Fallback: use runtime ID if available
+                return str(st.session_state.session_id)
             from streamlit.runtime.scriptrunner import get_script_run_ctx
             ctx = get_script_run_ctx()
             if ctx and hasattr(ctx, 'session_id'):
-                return ctx.session_id
-        except:
+                return str(ctx.session_id)
+        except Exception:
             pass
-        return None
+        import uuid
+        return str(uuid.uuid4())
     
     def is_security_enabled(self) -> bool:
         """Check if advanced security features are available."""
         return SECURITY_AVAILABLE and self.validator is not None
     
     def is_rate_limiting_enabled(self) -> bool:
         """Check if rate limiting is available."""
         return RATE_LIMITING_AVAILABLE and self.rate_limiter is not None
     
     def create_request_context(self, 
                               endpoint: str = "unknown",
                               request_size: int = 0,
                               user_id: Optional[str] = None) -> Optional[Any]:
         """Create RequestContext for DoS protection from Streamlit session."""
         if not DOS_PROTECTION_AVAILABLE or not RequestContext:
             return None
         
         try:
             import streamlit as st
             
             # Extract session information
             session_id = self._get_streamlit_session_id()
             
             # Get IP address (best effort - may not be available in all deployments)
             ip_address = self._get_client_ip() or "127.0.0.1"
@@ -674,52 +674,52 @@ class StreamlitSecurityManager:
             timestamp = str(int(time.time()))
             random_bytes = secrets.token_hex(16)
             
             # Create token payload
             token_data = f"{session_id}:{form_id}:{timestamp}:{random_bytes}"
             
             # Generate secure hash
             token_hash = hashlib.sha256(token_data.encode()).hexdigest()
             
             # Create final token (timestamp:hash for validation)
             csrf_token = f"{timestamp}:{token_hash}"
             
             # Store in session state for validation
             if hasattr(st, 'session_state'):
                 csrf_key = f"csrf_token_{form_id}"
                 st.session_state[csrf_key] = csrf_token
                 st.session_state[f"{csrf_key}_created"] = time.time()
             
             return csrf_token
             
         except Exception as e:
             if LOG_SANITIZATION_AVAILABLE:
                 self.logger.error(sanitize_log_message(f"Failed to generate CSRF token: {e}", 'ERROR'))
             else:
                 self.logger.error(f"Failed to generate CSRF token: {str(e)[:100]}")
-            # Fallback token
-            return hashlib.sha256(f"{form_id}:{time.time()}:{secrets.token_hex(8)}".encode()).hexdigest()[:16]
+            # Fallback robusto: manter alta entropia (~256 bits)
+            return secrets.token_urlsafe(32)
     
     def validate_csrf_token(self, form_id: str, provided_token: str, max_age_seconds: int = 3600) -> bool:
         """
         Validate a CSRF token for a form.
         
         Args:
             form_id: Unique identifier for the form
             provided_token: Token provided with form submission
             max_age_seconds: Maximum age of token in seconds (default 1 hour)
             
         Returns:
             True if token is valid, False otherwise
         """
         try:
             import streamlit as st
             
             if not provided_token:
                 return False
             
             # Get stored token from session
             if hasattr(st, 'session_state'):
                 csrf_key = f"csrf_token_{form_id}"
                 stored_token = st.session_state.get(csrf_key)
                 token_created = st.session_state.get(f"{csrf_key}_created", 0)
                 
 
EOF
)