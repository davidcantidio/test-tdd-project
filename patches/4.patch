*** a/intelligent_refactoring_engine.py
--- b/intelligent_refactoring_engine.py
@@
 from dataclasses import dataclass
 import sys
 import argparse
+from typing import Optional
 
 # Project setup
 project_root = Path(__file__).resolve().parent.parent.parent
 if str(project_root) not in sys.path:
     sys.path.insert(0, str(project_root))
@@
     RATE_LIMITER_AVAILABLE = False
     
 # Context Integration
 CONTEXT_BASE_PATH = Path(__file__).parent.parent / "context"
 GUIDES_PATH = CONTEXT_BASE_PATH / "guides"
 WORKFLOWS_PATH = CONTEXT_BASE_PATH / "workflows" 
 NAVIGATION_PATH = CONTEXT_BASE_PATH / "navigation"
@@
 class IntelligentRefactoringEngine:
@@
         self.logger = logging.getLogger(f"{__name__}.IntelligentRefactoringEngine")
         # Initialize intelligent rate limiter
         if RATE_LIMITER_AVAILABLE and enable_real_llm:
             self.rate_limiter = IntelligentRateLimiter()
             self.logger.info("✅ Intelligent Rate Limiter initialized for refactoring operations")
         else:
             self.rate_limiter = None
-            self.logger.warning("⚠️ Rate Limiter not available - using fallback timing")
+            self.logger.debug("ℹ️ Rate Limiter not available - using fallback timing")
@@
         self.refactoring_context = self._load_refactoring_context()
@@
         }
@@
         self.logger.info(
             "🔧 Intelligent Refactoring Engine initialized: real_llm=%s, budget=%d tokens, tdah=%s",
             enable_real_llm, tokens_budget, tdah_mode
         )
 
+    # ------------- Internal helpers -------------------------------------------------
+    def _rl_guard(self, estimated_tokens: int, bucket: str) -> None:
+        """
+        Centraliza verificação/espera/registro do rate limiter para reduzir duplicação.
+        No-ops caso o rate limiter não esteja disponível ou o modo LLM esteja desabilitado.
+        """
+        if not (self.enable_real_llm and self.rate_limiter):
+            return
+        if not self.rate_limiter.can_proceed(estimated_tokens, bucket):
+            sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, bucket)
+            # Evita logs ruidosos para sleeps muito curtos
+            if sleep_time >= 0.05:
+                self.logger.debug("⏰ Rate limiting [%s]: sleeping %.2fs", bucket, sleep_time)
+            time.sleep(sleep_time)
+        self.rate_limiter.record_usage(estimated_tokens, bucket)
+
@@
         self.logger.info("🧠 Applying LLM-powered extract method refactoring")
-        
-        # Check rate limiting
-        estimated_tokens = self.real_llm_config["extract_method_tokens"]
-        if self.rate_limiter and self.enable_real_llm:
-            if not self.rate_limiter.can_proceed(estimated_tokens, "extract_method"):
-                sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, "extract_method")
-                self.logger.info(f"⏰ Rate limiting: sleeping {sleep_time:.1f}s for method extraction")
-                time.sleep(sleep_time)
+        estimated_tokens = self.real_llm_config["extract_method_tokens"]
+        self._rl_guard(estimated_tokens, "extract_method")
@@
-            # Record token usage
-            if self.rate_limiter:
-                self.rate_limiter.record_usage(estimated_tokens, "extract_method")
-            
             # Simulate LLM-powered extraction
             # In production, would use actual LLM response
             extracted_method_name = "extracted_functionality"
             improvements = {
-                "complexity_reduction": 35.0,
-                "readability_improvement": 45.0,
-                "maintainability_increase": 40.0
+                "complexity_reduction": 35.0,        # percent (0-100)
+                "readability_improvement": 45.0,      # percent (0-100)
+                "maintainability_increase": 40.0      # percent (0-100)
             }
@@
         self.logger.info("🧠 Applying LLM-powered exception handling improvement")
-        
-        estimated_tokens = self.real_llm_config["exception_improvement_tokens"]
-        
-        if self.enable_real_llm:
-            # Check rate limiting
-            if self.rate_limiter:
-                if not self.rate_limiter.can_proceed(estimated_tokens, "exception_handling"):
-                    sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, "exception_handling")
-                    time.sleep(sleep_time)
-            
+        estimated_tokens = self.real_llm_config["exception_improvement_tokens"]
+        if self.enable_real_llm:
+            self._rl_guard(estimated_tokens, "exception_handling")
             # Real LLM analysis for exception improvement
             improvements = {
-                "error_coverage": 60.0,
-                "logging_quality": 55.0,
-                "recovery_capability": 50.0
+                "error_coverage": 60.0,      # percent
+                "logging_quality": 55.0,     # percent
+                "recovery_capability": 50.0  # percent
             }
-            
-            # Record token usage
-            if self.rate_limiter:
-                self.rate_limiter.record_usage(estimated_tokens, "exception_handling")
         else:
             # Fallback to pattern-based
             return self._apply_improve_exception_handling(lines, refactoring, file_path)
@@
         self.logger.info("🧠 Applying LLM-powered string optimization")
-        
-        estimated_tokens = self.real_llm_config["string_optimization_tokens"]
-        
-        if self.enable_real_llm and self.rate_limiter:
-            if not self.rate_limiter.can_proceed(estimated_tokens, "string_optimization"):
-                sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, "string_optimization")
-                time.sleep(sleep_time)
-            self.rate_limiter.record_usage(estimated_tokens, "string_optimization")
+        estimated_tokens = self.real_llm_config["string_optimization_tokens"]
+        if self.enable_real_llm:
+            self._rl_guard(estimated_tokens, "string_optimization")
@@
-        estimated_tokens = self.real_llm_config["god_code_analysis_tokens"]
-        
+        estimated_tokens = self.real_llm_config["god_code_analysis_tokens"]
         if self.enable_real_llm:
-            # Use the god code agent with real LLM capabilities
-            if self.rate_limiter:
-                if not self.rate_limiter.can_proceed(estimated_tokens, "god_method"):
-                    sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, "god_method")
-                    time.sleep(sleep_time)
+            # Use the god code agent with real LLM capabilities
+            self._rl_guard(estimated_tokens, "god_method")
@@
-            if self.rate_limiter:
-                self.rate_limiter.record_usage(estimated_tokens, "god_method")
-            
             improvements = {
                 "complexity_reduction": 65.0,
                 "responsibility_separation": 70.0,
                 "maintainability_increase": 60.0
             }
@@
         self.logger.info("🧠 Applying LLM-powered database query optimization")
-        
-        estimated_tokens = self.real_llm_config["query_optimization_tokens"]
-        
+        estimated_tokens = self.real_llm_config["query_optimization_tokens"]
         if self.enable_real_llm:
-            if self.rate_limiter:
-                if not self.rate_limiter.can_proceed(estimated_tokens, "query_optimization"):
-                    sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, "query_optimization")
-                    time.sleep(sleep_time)
-                self.rate_limiter.record_usage(estimated_tokens, "query_optimization")
+            self._rl_guard(estimated_tokens, "query_optimization")
             
             improvements = {
                 "query_reduction": 50.0,
                 "performance_gain": 45.0,
                 "database_load_reduction": 40.0
             }
@@
         self.logger.info("🧠 Applying LLM-powered constants extraction")
-        
-        estimated_tokens = self.real_llm_config["constants_extraction_tokens"]
-        
-        if self.enable_real_llm and self.rate_limiter:
-            if not self.rate_limiter.can_proceed(estimated_tokens, "constants_extraction"):
-                sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, "constants_extraction")
-                time.sleep(sleep_time)
-            self.rate_limiter.record_usage(estimated_tokens, "constants_extraction")
+        estimated_tokens = self.real_llm_config["constants_extraction_tokens"]
+        if self.enable_real_llm:
+            self._rl_guard(estimated_tokens, "constants_extraction")
@@
         self.logger.info("🧠 Applying LLM-powered conditional logic improvement")
-        
-        estimated_tokens = self.real_llm_config["conditional_logic_tokens"]
-        
+        estimated_tokens = self.real_llm_config["conditional_logic_tokens"]
         if self.enable_real_llm:
-            if self.rate_limiter:
-                if not self.rate_limiter.can_proceed(estimated_tokens, "conditional_logic"):
-                    sleep_time = self.rate_limiter.calculate_required_delay(estimated_tokens, "conditional_logic")
-                    time.sleep(sleep_time)
-                self.rate_limiter.record_usage(estimated_tokens, "conditional_logic")
+            self._rl_guard(estimated_tokens, "conditional_logic")
             
             improvements = {
                 "complexity_reduction": 40.0,
                 "readability_improvement": 50.0,
                 "logic_clarity": 45.0
             }
@@
     def _apply_optimize_string_operations(
         self, 
         lines: List[str], 
         refactoring: IntelligentRefactoring, 
         file_path: str
     ) -> RefactoringResult:
         """Apply string operation optimizations."""
@@
-            # Convert string concatenation to f-strings
-            if "+" in line and any(quote in line for quote in ['"', "'"]):
-                optimized_line = self._optimize_string_concatenation(line)
+            # Convert string concatenation to f-strings (best-effort)
+            if "+" in line and any(q in line for q in ('"', "'")):
+                optimized_line = self._optimize_string_concatenation(line)
                 if optimized_line != line:
                     refactored_lines[line_idx] = optimized_line
                     affected_lines.append(line_num)
-                    improvements["performance_improvement"] += 0.3
-                    improvements["readability_improvement"] += 0.5
+                    improvements["performance_improvement"] += 10.0  # percent (heurístico)
+                    improvements["readability_improvement"] += 15.0  # percent
@@
-        # Identify potential N+1 query patterns
+        # Identify potential N+1 query patterns (heurístico, não-destrutivo)
         for line_num in refactoring.target_lines:
             line_idx = line_num - 1
             line = lines[line_idx]
@@
-                        improvements["performance_improvement"] += 1.0
+                        improvements["performance_improvement"] += 5.0  # percent heurístico
@@
     def _apply_extract_constants(
         self, 
         lines: List[str], 
         refactoring: IntelligentRefactoring, 
         file_path: str
     ) -> RefactoringResult:
-        """Apply constant extraction for magic numbers and strings."""
+        """Apply constant extraction for magic numbers, com salvaguardas."""
         
         refactored_lines = lines.copy()
         affected_lines = []
         constants_to_add = []
-        improvements = {"maintainability_improvement": 0.0}
+        improvements = {"maintainability_improvement": 0.0}  # percent
+
+        # Precompute string literal spans para não mexer dentro de strings
+        def _string_spans(s: str) -> List[Tuple[int, int]]:
+            spans: List[Tuple[int, int]] = []
+            quote = None
+            start = -1
+            i = 0
+            while i < len(s):
+                ch = s[i]
+                if quote:
+                    if ch == "\\":
+                        i += 2
+                        continue
+                    if ch == quote:
+                        spans.append((start, i))
+                        quote = None
+                    i += 1
+                    continue
+                if ch in ("'", '"'):
+                    quote = ch
+                    start = i
+                i += 1
+            return spans
+        def _in_spans(idx: int, spans: List[Tuple[int, int]]) -> bool:
+            return any(a <= idx <= b for (a, b) in spans)
@@
-            # Find magic numbers
-            magic_numbers = re.findall(r'\b(\d+)\b', line)
-            for number in magic_numbers:
-                if int(number) > 10:  # Only extract significant numbers
-                    constant_name = f"MAGIC_NUMBER_{number}"
-                    constants_to_add.append((constant_name, number))
-                    
-                    # Replace in line
-                    refactored_lines[line_idx] = line.replace(number, constant_name)
-                    affected_lines.append(line_num)
-                    improvements["maintainability_improvement"] += 0.2
+            spans = _string_spans(line)
+            # Encontra números "nus" que não estão colados a letras/underscore (evita ident/versões)
+            for m in re.finditer(r'(?<![A-Za-z_])(\d+)(?![A-Za-z_])', line):
+                num_txt = m.group(1)
+                start_i = m.start(1)
+                # ignora se dentro de string
+                if _in_spans(start_i, spans):
+                    continue
+                num_val = int(num_txt)
+                # ignora números pequenos e anos comuns
+                if num_val <= 10 or 1900 <= num_val <= 2100:
+                    continue
+                constant_name = f"MAGIC_NUMBER_{num_val}"
+                constants_to_add.append((constant_name, num_txt))
+                # substitui apenas esta ocorrência
+                line = line[:m.start(1)] + constant_name + line[m.end(1):]
+                refactored_lines[line_idx] = line
+                affected_lines.append(line_num)
+                improvements["maintainability_improvement"] += 5.0  # percent heurístico
@@
-        """Generate the extracted method code."""
+        """Generate the extracted method code."""
@@
-        """Optimize string concatenation to use f-strings."""
-        # This is a simplified implementation
-        # In practice, this would need more sophisticated parsing
-        
-        # Pattern: "string" + variable + "string"
-        pattern = r'("[^"]*")\s*\+\s*(\w+)\s*\+\s*("[^"]*")'
-        match = re.search(pattern, line)
-        
-        if match:
-            str1, var, str2 = match.groups()
-            replacement = f'f{str1[:-1]}{{{var}}}{str2[1:]}'
-            return line.replace(match.group(0), replacement)
-        
-        return line
+        """Optimize string concatenation to use f-strings (best-effort sem AST)."""
+        # Casos simples: "a" + x + "b"  |  'a' + x + 'b'
+        patterns = [
+            (r'("([^"\\]|\\.)*")\s*\+\s*([A-Za-z_]\w*)\s*\+\s*("([^"\\]|\\.)*")', '"'),
+            (r"(\'([^'\\]|\\.)*\')\s*\+\s*([A-Za-z_]\w*)\s*\+\s*(\'([^'\\]|\\.)*\')", "'"),
+        ]
+        for pat, quote in patterns:
+            m = re.search(pat, line)
+            if not m:
+                continue
+            left, var, right = m.group(1), m.group(3), m.group(4)
+            # monta f-string preservando conteúdo
+            # remove aspas finais/iniciais para concatenar
+            fprefix = f"f{left[:-1]}"  # tira aspas finais
+            fsuffix = f"{right[1:]}"   # tira aspas iniciais
+            replacement = f"{fprefix}{{{var}}}{fsuffix}"
+            return line.replace(m.group(0), replacement)
+        return line
@@
-        return "Consider collecting IDs and using batch query: WHERE id IN (...)"
+        return "Consider collecting IDs and using batch query: WHERE id IN (...)"  # orientação não-destrutiva
@@
-    def apply_intelligent_refactorings(
+    def apply_intelligent_refactorings(
         self, 
-        analysis_result: Dict[str, Any], 
-        selected_strategies: List[int] = None
+        analysis_result: Dict[str, Any], 
+        selected_strategies: Optional[List[int]] = None
     ) -> Dict[str, Any]:
         """Apply intelligent refactorings based on analysis results - MetaAgent compatible method."""
@@
-            strategy_names = list(self.refactoring_strategies.keys())
+            strategy_names = list(self.refactoring_strategies.keys())
@@
-                # Create a simple refactoring for this strategy
-                refactoring = IntelligentRefactoring(
-                    refactoring_type=strategy_name,
-                    target_lines=[1],  # Simplified - would need real analysis
-                    description=f"Apply {strategy_name} refactoring",
-                    confidence=0.8
-                )
+                # Constrói com argumentos mínimos garantidos para evitar quebras entre versões
+                refactoring = IntelligentRefactoring(
+                    refactoring_type=strategy_name,
+                    target_lines=[1],  # Simplificado – em produção viria do analyzer
+                    description=f"Apply {strategy_name} refactoring"
+                )
+                # Campos opcionais (defensivo)
+                for name, value in (
+                    ("confidence", 0.8),
+                    ("confidence_score", 0.8),
+                ):
+                    try:
+                        setattr(refactoring, name, value)
+                    except Exception:
+                        pass
@@
-                        # Estimate tokens used for this operation
-                        total_tokens_used += 150  # Rough estimate per refactoring
+                        # Estimate tokens used for this operation
+                        total_tokens_used += 150  # Rough estimate per refactoring
@@
 def main():
@@
-    parser.add_argument("--apply", action="store_true", help="Apply refactoring (not just analyze)")
+    parser.add_argument("--apply", action="store_true", help="Apply refactoring (writes file). If omitted, runs in dry-run mode.")
     parser.add_argument("--dry-run", action="store_true", help="Show what would be done")
     parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output")
@@
-        engine = IntelligentRefactoringEngine(dry_run=args.dry_run or not args.apply)
+        engine = IntelligentRefactoringEngine(dry_run=args.dry_run or not args.apply)
@@
-        if args.refactoring_type:
-            # Create a sample refactoring (in practice, this would come from analysis)
-            refactoring = IntelligentRefactoring(
-                refactoring_type=args.refactoring_type,
-                target_lines=[1, 2, 3],  # Sample lines
-                description=f"Apply {args.refactoring_type} refactoring",
-                benefits=["Improved code quality"],
-                risks=["Minimal"],
-                confidence_score=0.85,
-                estimated_impact={"maintainability": "high_improvement"}
-            )
+        if args.refactoring_type:
+            # Constrói refactoring com argumentos mínimos (compatível entre versões)
+            refactoring = IntelligentRefactoring(
+                refactoring_type=args.refactoring_type,
+                target_lines=[1, 2, 3],  # Exemplo; em produção deve vir da análise
+                description=f"Apply {args.refactoring_type} refactoring"
+            )
+            # Seta atributos opcionais se existirem (defensivo, sem quebrar)
+            for name, value in (
+                ("benefits", ["Improved code quality"]),
+                ("risks", ["Minimal"]),
+                ("confidence", 0.85),
+                ("confidence_score", 0.85),
+                ("estimated_impact", {"maintainability": "high_improvement"}),
+            ):
+                try:
+                    setattr(refactoring, name, value)
+                except Exception:
+                    pass
@@
-            print(f"\n🔧 Refactoring Results for {args.file}")
+            print(f"\n🔧 Refactoring Results for {args.file}")
             print(f"=" * 50)
             print(f"Type: {result.refactoring_type}")
             print(f"Success: {result.success}")
             print(f"Lines affected: {len(result.lines_affected)}")
@@
-                for improvement, value in result.improvements.items():
-                    print(f"  {improvement}: {value:.1f}")
+                for improvement, value in result.improvements.items():
+                    try:
+                        print(f"  {improvement}: {float(value):.1f}")
+                    except Exception:
+                        print(f"  {improvement}: {value}")
@@
-            project_root = Path(__file__).resolve().parent.parent.parent
+            project_root = Path(__file__).resolve().parent.parent.parent
             agent = IntelligentCodeAgent(project_root=project_root, dry_run=True)
@@
-                    if result.success:
+                    if result.success:
                         print(f"   ✅ Applied successfully")
                     else:
                         print(f"   ❌ Failed: {result.errors}")
