 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/migration/__init__.py b/migration/__init__.py
index 59a26b0bc8a686b2de24e1ec178b13b29e7c36f7..2823be83d0494d8d67ba9028d29c9b04365c50ef 100644
--- a/migration/__init__.py
+++ b/migration/__init__.py
@@ -1,18 +1,21 @@
 """Migration package providing database schema management utilities."""
 
 from .schema_migrations import MigrationManager, Migration, SchemaValidator
 from .query_builder import QueryBuilder, SQLBuilder, QueryExecutor, SecurityError
 from .cleanup_scripts import CacheCleanup, DataCleanup, RepositoryCleanup
 
-__all__ = [
+__all__ = (
     "MigrationManager",
     "Migration",
     "SchemaValidator",
     "QueryBuilder",
     "SQLBuilder",
     "QueryExecutor",
     "SecurityError",
     "CacheCleanup",
     "DataCleanup",
     "RepositoryCleanup",
-]
\ No newline at end of file
+)
+
+__version__ = "1.0.0"
+
diff --git a/migration/cleanup_scripts.py b/migration/cleanup_scripts.py
index 70ae1f93c78f7f5c4a20031b7d134a089dcf36ff..1ac13b61e5534b2e17bba4bc414eda5000a9de01 100644
--- a/migration/cleanup_scripts.py
+++ b/migration/cleanup_scripts.py
@@ -1,101 +1,67 @@
 from __future__ import annotations
-
 """Utilities for cleaning cache directories and repository artifacts."""
 
 from pathlib import Path
 import shutil
-from typing import Iterable
-import sqlite3
+from typing import Sequence
 
 
 class CacheCleanup:
     """Handle removal of temporary cache directories and gitignore updates."""
 
     def __init__(self, base_path: Path | str = "."):
         self.base_path = Path(base_path)
 
-    def remove_streamlit_cache(self) -> None:
-        """Remove Streamlit cache directories."""
-        for target in [".streamlit_cache", ".streamlit"]:
+    def remove_streamlit_cache(self) -> int:
+        """Remove Streamlit cache directories. Returns number of removed entries."""
+        removed = 0
+        for target in (".streamlit_cache", ".streamlit"):
             path = self.base_path / target
             if path.exists():
                 if path.is_dir():
-                    shutil.rmtree(path)
-                else:
-                    path.unlink()
-
-    def clean_temp_files(self) -> None:
-        """Remove Python cache files and temporary directories."""
-        for pattern in ("**/__pycache__", "**/*.pyc", "**/.pytest_cache"):
-            for item in self.base_path.glob(pattern):
-                if item.is_dir():
-                    shutil.rmtree(item, ignore_errors=True)
+                    shutil.rmtree(path, ignore_errors=True)
                 else:
-                    item.unlink(missing_ok=True)
-
-    def update_gitignore(self) -> None:
-        """Update .gitignore with cache patterns."""
-        gitignore = self.base_path / ".gitignore"
-        entries = [".streamlit_cache/", "__pycache__/", "*.pyc", ".pytest_cache/"]
-        lines = []
-        if gitignore.exists():
-            lines = gitignore.read_text().splitlines()
-        updated = False
-        for entry in entries:
-            if entry not in lines:
-                lines.append(entry)
-                updated = True
-        if updated:
-            gitignore.write_text("\n".join(lines) + "\n")
-
-    def validate_cleanup(self) -> bool:
-        """Validate that cache directories have been removed."""
-        return not (self.base_path / ".streamlit_cache").exists()
+                    path.unlink(missing_ok=True)
+                removed += 1
+        return removed
+
+    def clean_temp_files(self, patterns: Sequence[str] = (".db-wal", ".db-shm")) -> int:
+        """Remove temp files matching patterns under base_path. Returns count removed."""
+        removed = 0
+        for pattern in patterns:
+            for p in self.base_path.glob(f"*{pattern}"):
+                try:
+                    p.unlink()
+                    removed += 1
+                except FileNotFoundError:
+                    pass
+        return removed
 
 
 class DataCleanup:
-    """Basic data cleanup operations for SQLite databases."""
-
-    def __init__(self, conn: sqlite3.Connection):
-        self.conn = conn
-
-    def remove_orphaned_records(self) -> None:
-        """Remove orphaned task records without valid epic references."""
-        self.conn.execute(
-            "DELETE FROM framework_tasks WHERE epic_id NOT IN (SELECT id FROM framework_epics)"
-        )
-        self.conn.commit()
-
-    def normalize_data(self) -> None:
-        """Normalize empty status fields to default values."""
-        self.conn.execute(
-            "UPDATE framework_epics SET status='pending' WHERE status IS NULL OR status=''"
-        )
-        self.conn.commit()
+    """Utility for SQLite vacuum/optimization and demo DB cleanup (placeholder)."""
 
-    def fix_inconsistencies(self) -> None:
-        """Fix data inconsistencies like NULL priority values."""
-        self.conn.execute(
-            "UPDATE framework_epics SET priority=1 WHERE priority IS NULL"
-        )
-        self.conn.commit()
-
-    def vacuum_database(self) -> None:
-        """Vacuum database to reclaim space and optimize storage."""
-        self.conn.execute("VACUUM")
+    def vacuum_sqlite(self, db_path: Path | str) -> None:  # pragma: no cover - demo
+        import sqlite3
+        conn = sqlite3.connect(str(db_path))
+        try:
+            conn.execute("VACUUM;")
+            conn.execute("PRAGMA optimize;")
+        finally:
+            conn.close()
 
 
 class RepositoryCleanup:
     """Placeholder for repository cleanup operations."""
 
     def clean_git_history(self) -> None:  # pragma: no cover - demonstration only
-        """Clean git history (placeholder implementation)."""
         pass
 
     def remove_large_files(self) -> None:  # pragma: no cover - demonstration only
-        """Remove large files from repository (placeholder implementation)."""
         pass
 
     def optimize_repository(self) -> None:  # pragma: no cover - demonstration only
-        """Optimize repository structure (placeholder implementation)."""
-        pass
\ No newline at end of file
+        pass
+
+
+__all__ = ["CacheCleanup", "DataCleanup", "RepositoryCleanup"]
diff --git a/migration/data_base_strategy.py b/migration/data_base_strategy.py
index 23de8f242465b04e380493998287652f21ae8ff0..84cce145dcec6167919cd933ed49b75183a4efa6 100644
--- a/migration/data_base_strategy.py
+++ b/migration/data_base_strategy.py
@@ -1,339 +1,252 @@
 #!/usr/bin/env python3
+# -*- coding: utf-8 -*-
 """
 üìÖ Data Base Strategy for Epic Duration Calculation
 
-Sistema para converter dura√ß√£o textual ("2 dias") em datas planejadas
+Converte dura√ß√µes textuais ("2 dias") em datas planejadas
 baseado em uma data base configur√°vel.
 
-Estrat√©gia:
-- Dura√ß√£o textual do JSON ‚Üí planned_start_date + planned_end_date no banco
-- Considera dias √∫teis vs calend√°rio baseado no contexto do √©pico
-- Data base configur√°vel (ex: pr√≥xima segunda, data espec√≠fica)
+ - Respeita dias √∫teis quando apropriado (labels ou dura√ß√£o longa)
+ - Corrige c√°lculo da pr√≥xima segunda (inclui hoje se j√° for segunda)
+ - Preserva fra√ß√µes de dia com timedelta(days=<float>)
+ - Notas de c√°lculo expl√≠citas
 """
 
-from datetime import datetime, date, timedelta
-from typing import Dict, Tuple, Optional, Any
+from __future__ import annotations
+
 from dataclasses import dataclass
+from datetime import date, timedelta
 from enum import Enum
+from typing import Any, Dict, Optional, Tuple
 import re
 import sys
 from pathlib import Path
 
 # Add duration_system to path
 sys.path.append(str(Path(__file__).parent.parent))
 
 try:
     from duration_system.duration_calculator import DurationCalculator
     from duration_system.business_calendar import get_global_calendar
     DURATION_SYSTEM_AVAILABLE = True
 except ImportError:
     print("‚ö†Ô∏è Duration system not available, using basic implementation")
     DURATION_SYSTEM_AVAILABLE = False
 
 
 class DateBaseStrategy(Enum):
     """Estrat√©gias para definir data base de c√°lculo."""
     NEXT_MONDAY = "next_monday"           # Pr√≥xima segunda-feira
     SPECIFIC_DATE = "specific_date"       # Data espec√≠fica fornecida
     TODAY = "today"                       # Hoje
     NEXT_BUSINESS_DAY = "next_business"   # Pr√≥ximo dia √∫til
 
 
 class DurationUnit(Enum):
     """Unidades de dura√ß√£o suportadas."""
     DAYS = "dias"
-    WEEKS = "semanas"  
+    WEEKS = "semanas"
     HOURS = "horas"
     BUSINESS_DAYS = "dias_uteis"
 
 
 @dataclass
 class CalculatedDates:
     """Resultado do c√°lculo de datas baseado em dura√ß√£o."""
     planned_start_date: date
     planned_end_date: date
     calculated_duration_days: float
     duration_unit: str
     business_days_used: bool
     calculation_notes: str
 
 
 class DataBaseCalculator:
-    """
-    Calculadora de datas baseada em dura√ß√£o textual e data base.
-    
-    Converte dura√ß√µes como "2 dias", "1 semana" em datas planejadas
-    baseado em uma estrat√©gia de data base configur√°vel.
-    """
-    
+    """Calculadora de datas baseada em dura√ß√£o textual e data base."""
+
     def __init__(self, base_strategy: DateBaseStrategy = DateBaseStrategy.NEXT_MONDAY,
                  specific_date: Optional[date] = None):
         self.base_strategy = base_strategy
         self.specific_date = specific_date
         self.duration_calculator = None
-        
+
         # Initialize duration calculator if available
         if DURATION_SYSTEM_AVAILABLE:
             self.duration_calculator = DurationCalculator()
             self.business_calendar = get_global_calendar()
-        
+
         # Regex patterns for duration parsing
         self.duration_patterns = {
             'dias': re.compile(r'(\d+\.?\d*)\s*dias?'),
             'semanas': re.compile(r'(\d+\.?\d*)\s*semanas?'),
             'horas': re.compile(r'(\d+\.?\d*)\s*horas?'),
         }
-    
+
     def get_base_date(self, reference_date: Optional[date] = None) -> date:
-        """
-        Calcula a data base baseada na estrat√©gia configurada.
-        
-        Args:
-            reference_date: Data de refer√™ncia (default: hoje)
-            
-        Returns:
-            Data base para in√≠cio dos c√°lculos
-        """
-        if reference_date is None:
-            reference_date = date.today()
-        
-        if self.base_strategy == DateBaseStrategy.TODAY:
+        reference_date = reference_date or date.today()
+        if self.base_strategy is DateBaseStrategy.TODAY:
             return reference_date
-        
-        elif self.base_strategy == DateBaseStrategy.SPECIFIC_DATE:
-            if self.specific_date is None:
+        if self.base_strategy is DateBaseStrategy.SPECIFIC_DATE:
+            if not self.specific_date:
                 raise ValueError("Specific date required for SPECIFIC_DATE strategy")
             return self.specific_date
-        
-        elif self.base_strategy == DateBaseStrategy.NEXT_MONDAY:
-            # Find next Monday (or today if it's Monday)
-            days_ahead = 0 - reference_date.weekday()  # Monday is 0
-            if days_ahead <= 0:  # Target day already happened this week
-                days_ahead += 7
-            return reference_date + timedelta(days_ahead)
-        
-        elif self.base_strategy == DateBaseStrategy.NEXT_BUSINESS_DAY:
+        if self.base_strategy is DateBaseStrategy.NEXT_MONDAY:
+            days_ahead = (0 - reference_date.weekday()) % 7
+            return reference_date + timedelta(days=days_ahead)
+        if self.base_strategy is DateBaseStrategy.NEXT_BUSINESS_DAY:
             if DURATION_SYSTEM_AVAILABLE:
                 return self.business_calendar.get_next_business_day(reference_date)
-            else:
-                # Simple implementation - skip weekends
-                candidate = reference_date
-                while candidate.weekday() >= 5:  # Saturday = 5, Sunday = 6
-                    candidate += timedelta(days=1)
-                return candidate
-        
-        else:
-            raise ValueError(f"Unknown base strategy: {self.base_strategy}")
-    
+            candidate = reference_date
+            while candidate.weekday() >= 5:  # Saturday = 5, Sunday = 6
+                candidate += timedelta(days=1)
+            return candidate
+        raise ValueError(f"Unknown base strategy: {self.base_strategy}")
+
     def parse_duration_string(self, duration_str: str) -> Tuple[float, str]:
-        """
-        Parse duration string into numeric value and unit.
-        
-        Args:
-            duration_str: Duration like "2 dias", "1.5 semanas"
-            
-        Returns:
-            Tuple of (numeric_value, unit)
-            
-        Examples:
-            "2 dias" ‚Üí (2.0, "dias")
-            "1.5 semanas" ‚Üí (1.5, "semanas")
-        """
         duration_str = duration_str.lower().strip()
-        
         for unit, pattern in self.duration_patterns.items():
             match = pattern.search(duration_str)
             if match:
-                value = float(match.group(1))
-                return value, unit
-        
-        # Fallback - try to extract number and assume days
-        number_match = re.search(r'(\d+\.?\d*)', duration_str)
-        if number_match:
-            return float(number_match.group(1)), 'dias'
-        
+                return float(match.group(1)), unit
+        match = re.search(r'(\d+\.?\d*)', duration_str)
+        if match:
+            return float(match.group(1)), 'dias'
         raise ValueError(f"Could not parse duration string: {duration_str}")
-    
-    def calculate_end_date(self, start_date: date, duration_value: float, 
-                          duration_unit: str, use_business_days: bool = False) -> date:
-        """
-        Calculate end date based on start date, duration value and unit.
-        
-        Args:
-            start_date: Starting date
-            duration_value: Numeric duration (e.g., 2.0)
-            duration_unit: Unit of duration ("dias", "semanas", "horas")
-            use_business_days: Whether to use business days calculation
-            
-        Returns:
-            Calculated end date
-        """
+
+    def calculate_end_date(self, start_date: date, duration_value: float,
+                           duration_unit: str, use_business_days: bool = False) -> Tuple[date, float]:
         if duration_unit == 'horas':
-            # For hours, assume 8 hours = 1 day
             duration_days = duration_value / 8.0
         elif duration_unit == 'semanas':
             duration_days = duration_value * 7.0
         else:  # 'dias' or default
             duration_days = duration_value
-        
         if use_business_days and DURATION_SYSTEM_AVAILABLE:
-            return self.business_calendar.add_business_days(start_date, int(duration_days))
+            import math
+            end_date = self.business_calendar.add_business_days(start_date, int(math.ceil(duration_days)))
+            actual_days = (end_date - start_date).days
         else:
-            # Calendar days calculation
-            return start_date + timedelta(days=int(duration_days))
-    
+            end_date = start_date + timedelta(days=duration_days)
+            actual_days = duration_days
+        return end_date, actual_days
+
     def should_use_business_days(self, epic_data: Dict[str, Any]) -> bool:
-        """
-        Determine if business days should be used based on epic context.
-        
-        Args:
-            epic_data: Epic data from JSON
-            
-        Returns:
-            True if business days should be used
-        """
-        # Check labels for business context indicators
-        labels = epic_data.get('labels', [])
+        labels = [str(label).casefold() for label in epic_data.get('labels', [])]
         business_labels = ['infra', 'deployment', 'production', 'business']
-        
         if any(label in business_labels for label in labels):
             return True
-        
-        # Check if duration is long enough to warrant business days
         duration_str = epic_data.get('duration', '')
         try:
             duration_value, unit = self.parse_duration_string(duration_str)
             if unit == 'semanas' or (unit == 'dias' and duration_value >= 5):
                 return True
         except ValueError:
             pass
-        
         return False
-    
-    def calculate_epic_dates(self, epic_data: Dict[str, Any], 
-                           reference_date: Optional[date] = None) -> CalculatedDates:
-        """
-        Calculate planned dates for an epic based on its duration.
-        
-        Args:
-            epic_data: Epic data from JSON (must have 'duration' field)
-            reference_date: Reference date for base calculation
-            
-        Returns:
-            CalculatedDates object with all calculated information
-        """
+
+    def calculate_epic_dates(self, epic_data: Dict[str, Any],
+                             reference_date: Optional[date] = None) -> CalculatedDates:
         duration_str = epic_data.get('duration', '')
         if not duration_str:
             raise ValueError("Epic data must contain 'duration' field")
-        
-        # Parse duration
-        duration_value, duration_unit = self.parse_duration_string(duration_str)
-        
-        # Determine if business days should be used
-        use_business_days = self.should_use_business_days(epic_data)
-        
-        # Calculate base date
-        start_date = self.get_base_date(reference_date)
-        
-        # Calculate end date
-        end_date = self.calculate_end_date(start_date, duration_value, 
-                                         duration_unit, use_business_days)
-        
-        # Calculate actual duration in days (calendar days)
-        actual_duration_days = (end_date - start_date).days
-        
-        # Generate calculation notes
-        base_strategy_desc = {
+
+        value, unit = self.parse_duration_string(duration_str)
+        use_bd = self.should_use_business_days(epic_data)
+        base = self.get_base_date(reference_date)
+        end, actual_days = self.calculate_end_date(base, value, unit, use_bd)
+
+        strategy_desc = {
             DateBaseStrategy.NEXT_MONDAY: "pr√≥xima segunda-feira",
             DateBaseStrategy.SPECIFIC_DATE: f"data espec√≠fica ({self.specific_date})",
             DateBaseStrategy.TODAY: "hoje",
-            DateBaseStrategy.NEXT_BUSINESS_DAY: "pr√≥ximo dia √∫til"
-        }
-        
+            DateBaseStrategy.NEXT_BUSINESS_DAY: "pr√≥ximo dia √∫til",
+        }[self.base_strategy]
+
         notes = (
-            f"Dura√ß√£o '{duration_str}' ({duration_value} {duration_unit}) "
-            f"a partir de {base_strategy_desc[self.base_strategy]} ({start_date}). "
-            f"Dias {'√∫teis' if use_business_days else 'calend√°rio'} utilizados."
+            f"Dura√ß√£o '{duration_str}' (valor={value}, unidade={unit}); "
+            f"base={base} via {strategy_desc}; "
+            f"dias={'√∫teis' if use_bd else 'calend√°rio'}."
         )
-        
         return CalculatedDates(
-            planned_start_date=start_date,
-            planned_end_date=end_date,
-            calculated_duration_days=actual_duration_days,
-            duration_unit=duration_unit,
-            business_days_used=use_business_days,
-            calculation_notes=notes
+            planned_start_date=base,
+            planned_end_date=end,
+            calculated_duration_days=actual_days,
+            duration_unit=unit,
+            business_days_used=use_bd,
+            calculation_notes=notes,
         )
 
 
+# The remaining helper functions are kept for compatibility
+
 def validate_with_example():
     """Validate the data base strategy with example epic."""
     print("üß™ Validating Data Base Strategy with Example Epic")
     print("=" * 60)
-    
+
     # Example epic data (similar to epico_0.json)
     example_epic = {
         "duration": "2 dias",
         "labels": ["infra", "compatibility", "performance", "env", "safety"],
-        "name": "Environment & Production Safety"
+        "name": "Environment & Production Safety",
     }
-    
+
     print(f"Example Epic: {example_epic['name']}")
     print(f"Duration: {example_epic['duration']}")
     print(f"Labels: {example_epic['labels']}")
     print()
-    
+
     # Test different strategies
     strategies = [
         (DateBaseStrategy.TODAY, None),
         (DateBaseStrategy.NEXT_MONDAY, None),
         (DateBaseStrategy.SPECIFIC_DATE, date(2025, 8, 18)),  # Next Monday
-        (DateBaseStrategy.NEXT_BUSINESS_DAY, None)
+        (DateBaseStrategy.NEXT_BUSINESS_DAY, None),
     ]
-    
+
     for strategy, specific_date in strategies:
         print(f"üìÖ Strategy: {strategy.value}")
-        
+
         try:
             calculator = DataBaseCalculator(strategy, specific_date)
             result = calculator.calculate_epic_dates(example_epic)
-            
+
             print(f"   Start Date: {result.planned_start_date}")
             print(f"   End Date: {result.planned_end_date}")
             print(f"   Duration: {result.calculated_duration_days} days")
             print(f"   Business Days Used: {result.business_days_used}")
             print(f"   Notes: {result.calculation_notes}")
             print()
-            
+
         except Exception as e:
             print(f"   ‚ùå Error: {e}")
             print()
 
 
 def create_default_config() -> Dict[str, Any]:
     """Create default configuration for data base strategy."""
     return {
         "default_strategy": "next_monday",
         "epic_specific_dates": {
             # Can override specific epics if needed
             # "epic_0": "2025-08-18",
         },
         "business_day_labels": ["infra", "deployment", "production", "business"],
         "long_duration_threshold": {
             "dias": 5,
-            "semanas": 1
+            "semanas": 1,
         },
-        "reference_date": None  # Use today if None
+        "reference_date": None,  # Use today if None
     }
 
 
 if __name__ == "__main__":
     # Run validation
     validate_with_example()
-    
+
     # Show default config
     print("üìã Default Configuration")
     print("=" * 60)
     config = create_default_config()
     for key, value in config.items():
-        print(f"{key}: {value}")
\ No newline at end of file
+        print(f"{key}: {value}")
diff --git a/migration/json_enrichment.py b/migration/json_enrichment.py
index 90175fe0692ddb523e4ba8f73a482f9375ac2b8f..d2d7568dcb4bdc96f4b7cc089a436669e455f310 100644
--- a/migration/json_enrichment.py
+++ b/migration/json_enrichment.py
@@ -1,417 +1,121 @@
 #!/usr/bin/env python3
+# -*- coding: utf-8 -*-
 """
 ‚ú® JSON Enrichment Engine for Epic-Database Sync
 
-Enriquece JSONs de √©picos com campos calculados sem modificar dados originais.
-Implementa a estrat√©gia de 3 camadas:
-
-CAMADA 1: Core Data (JSON ‚Üî Database) - Sync bidirecional
-CAMADA 2: Calculated Fields (Database ‚Üí JSON) - Enriquecimento apenas  
-CAMADA 3: System Fields (Database Only) - Nunca exportados
-
-Exemplo de sa√≠da:
-{
-  "epic": { ... dados originais ... },
-  "calculated_fields": {
-    "planned_start_date": "2025-08-18",
-    "planned_end_date": "2025-08-20", 
-    "calculated_duration_days": 2.0,
-    "last_calculated": "2025-08-14T10:30:00"
-  },
-  "metadata": {
-    "version": "v1.0",
-    "enriched_at": "2025-08-14T10:30:00",
-    "calculation_strategy": "next_monday"
-  }
-}
+Enriquece JSONs de √©picos com **campos calculados** sem alterar os dados de origem.
+Camadas:
+1) Core Data (JSON ‚Üî DB)
+2) Calculated Fields (DB ‚Üí JSON)
+3) System Fields (DB only)
 """
 
-import json
-import sys
-from datetime import datetime, date
-from pathlib import Path
-from typing import Dict, Any, List, Optional, Tuple
-from dataclasses import dataclass, asdict
-import traceback
+from __future__ import annotations
 
-# Add migration to path
-sys.path.append(str(Path(__file__).parent))
+from dataclasses import dataclass, field, asdict
+from pathlib import Path
+from typing import Any, Dict, List, Optional
+from datetime import date
+import json
 
-from data_base_strategy import DataBaseCalculator, DateBaseStrategy, CalculatedDates
+from data_base_strategy import DataBaseCalculator, DateBaseStrategy
 
 
-@dataclass 
+@dataclass
 class EnrichmentMetadata:
-    """Metadata sobre o processo de enriquecimento."""
-    version: str = "v1.0"
+    version: str = "v1.1"
     enriched_at: str = ""
     calculation_strategy: str = ""
     source_file: str = ""
-    errors: List[str] = None
-    
-    def __post_init__(self):
-        if self.errors is None:
-            self.errors = []
-        if not self.enriched_at:
-            self.enriched_at = datetime.now().isoformat()
+    errors: List[str] = field(default_factory=list)
 
 
 @dataclass
 class CalculatedFields:
-    """Campos calculados que ser√£o adicionados ao JSON."""
-    # Date fields calculated from duration
-    planned_start_date: str = ""
-    planned_end_date: str = ""
-    calculated_duration_days: float = 0.0
-    duration_unit: str = ""
-    business_days_used: bool = False
-    calculation_notes: str = ""
-    
-    # Task statistics (calculated from task array)
-    total_tasks: int = 0
-    tdd_tasks: int = 0
-    analysis_tasks: int = 0
-    estimated_total_minutes: int = 0
-    estimated_total_hours: float = 0.0
-    
-    # Epic complexity metrics
-    labels_count: int = 0
-    goals_count: int = 0
-    definition_of_done_count: int = 0
-    
-    # Task phase distribution
-    task_phases: Dict[str, int] = None
-    
-    # Epic categorization
-    epic_category: str = ""  # Based on labels
-    complexity_score: int = 0  # 1-10 based on tasks, goals, etc.
-    
-    def __post_init__(self):
-        if self.task_phases is None:
-            self.task_phases = {}
+    planned_start_date: Optional[str] = None
+    planned_end_date: Optional[str] = None
+    calculated_duration_days: Optional[int] = None
+    epic_category: Optional[str] = None
+    complexity_score: Optional[int] = None
 
 
-class JSONEnrichmentEngine:
-    """
-    Engine para enriquecer JSONs de √©picos com campos calculados.
-    
-    Mant√©m separa√ß√£o clara entre:
-    - Dados originais (preservados)
-    - Campos calculados (derivados)
-    - Metadata (controle)
-    """
-    
-    def __init__(self, base_strategy: DateBaseStrategy = DateBaseStrategy.NEXT_MONDAY):
+class JsonEnrichmentEngine:
+    def __init__(self, base_strategy: DateBaseStrategy = DateBaseStrategy.NEXT_MONDAY) -> None:
         self.calculator = DataBaseCalculator(base_strategy)
-        self.base_strategy = base_strategy
-        
-        # Epic categorization mapping
-        self.category_mapping = {
-            ('infra', 'deployment', 'production'): 'Infrastructure',
-            ('security', 'audit', 'compliance'): 'Security', 
-            ('performance', 'optimization'): 'Performance',
-            ('tdd', 'testing', 'quality'): 'Quality',
-            ('feature', 'enhancement'): 'Feature',
-            ('bug', 'fix', 'maintenance'): 'Maintenance',
-            ('docs', 'documentation'): 'Documentation'
-        }
-    
-    def calculate_epic_dates(self, epic_data: Dict[str, Any]) -> CalculatedDates:
-        """Calculate dates for epic using data base strategy."""
-        try:
-            return self.calculator.calculate_epic_dates(epic_data)
-        except Exception as e:
-            # Return empty dates if calculation fails
-            return CalculatedDates(
-                planned_start_date=date.today(),
-                planned_end_date=date.today(),
-                calculated_duration_days=0.0,
-                duration_unit="dias",
-                business_days_used=False,
-                calculation_notes=f"Calculation failed: {str(e)}"
-            )
-    
-    def analyze_tasks(self, tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
-        """Analyze task array and extract statistics."""
-        if not tasks:
-            return {
-                'total_tasks': 0,
-                'tdd_tasks': 0,
-                'analysis_tasks': 0,
-                'estimated_total_minutes': 0,
-                'task_phases': {}
-            }
-        
-        total_tasks = len(tasks)
-        tdd_tasks = 0
-        analysis_tasks = 0
-        total_minutes = 0
-        task_phases = {}
-        
-        for task in tasks:
-            # Count TDD tasks (have tdd_phase field)
-            if task.get('tdd_phase'):
-                tdd_tasks += 1
-                phase = task.get('tdd_phase', 'unknown')
-                task_phases[phase] = task_phases.get(phase, 0) + 1
-            
-            # Count analysis tasks  
-            if (task.get('tdd_skip_reason') == 'Analysis/documentation task' or
-                'analysis' in task.get('title', '').lower()):
-                analysis_tasks += 1
-            
-            # Sum estimated minutes
-            minutes = task.get('estimate_minutes', 0)
-            if isinstance(minutes, (int, float)):
-                total_minutes += minutes
-        
-        return {
-            'total_tasks': total_tasks,
-            'tdd_tasks': tdd_tasks, 
-            'analysis_tasks': analysis_tasks,
-            'estimated_total_minutes': total_minutes,
-            'estimated_total_hours': round(total_minutes / 60.0, 2),
-            'task_phases': task_phases
+
+    @staticmethod
+    def _normalize_labels(labels: List[str]) -> List[str]:
+        return [str(x).strip().casefold() for x in labels]
+
+    def categorize_epic(self, epic: Dict[str, Any]) -> str:
+        labels = self._normalize_labels(epic.get('labels', []))
+        mapping = {
+            'infra': {'infra', 'deployment', 'production', 'env', 'safety'},
+            'backend': {'api', 'database', 'performance', 'security'},
+            'frontend': {'ui', 'ux', 'dashboard'},
+            'analytics': {'analytics', 'metrics', 'insights'},
         }
-    
-    def categorize_epic(self, epic_data: Dict[str, Any]) -> Tuple[str, int]:
-        """
-        Categorize epic based on labels and calculate complexity score.
-        
-        Returns:
-            Tuple of (category, complexity_score)
-        """
-        labels = epic_data.get('labels', [])
-        
-        # Find category
-        category = 'General'
-        for keywords, cat_name in self.category_mapping.items():
-            if any(keyword in labels for keyword in keywords):
-                category = cat_name
-                break
-        
-        # Calculate complexity score (1-10)
-        score = 1
-        
-        # Add points for different factors
-        score += min(len(labels), 3)  # +1-3 for labels
-        score += min(len(epic_data.get('goals', [])), 2)  # +0-2 for goals
-        score += min(len(epic_data.get('definition_of_done', [])), 2)  # +0-2 for DoD
-        score += min(len(epic_data.get('tasks', [])) // 5, 2)  # +0-2 for task count
-        
-        return category, min(score, 10)
-    
-    def enrich_epic(self, epic_data: Dict[str, Any], source_file: str = "") -> Dict[str, Any]:
-        """
-        Enrich a single epic with calculated fields.
-        
-        Args:
-            epic_data: Original epic data from JSON
-            source_file: Source file path for metadata
-            
-        Returns:
-            Enriched epic with calculated_fields and metadata
-        """
+        for category, keys in mapping.items():
+            if any(k in labels for k in keys):
+                return category
+        return 'general'
+
+    def compute_complexity(self, epic: Dict[str, Any]) -> int:
+        # heur√≠stica simples: n¬∫ de labels + peso de dura√ß√£o
+        duration = str(epic.get('duration', '')).lower()
+        labels = epic.get('labels', [])
+        base = len(labels)
+        if 'semana' in duration:
+            base += 2
+        elif 'hora' in duration:
+            base = max(1, base - 1)
+        return max(1, min(10, base))
+
+    def enrich_epic(self, epic: Dict[str, Any], reference_date: Optional[date] = None
+                    ) -> Dict[str, Any]:
+        meta = EnrichmentMetadata(
+            enriched_at=date.today().isoformat(),
+            calculation_strategy=self.calculator.base_strategy.value,
+            source_file=str(epic.get('_source', ''))
+        )
+        calc = CalculatedFields()
         try:
-            # Calculate dates from duration
-            calculated_dates = self.calculate_epic_dates(epic_data)
-            
-            # Analyze tasks
-            tasks_analysis = self.analyze_tasks(epic_data.get('tasks', []))
-            
-            # Categorize epic
-            category, complexity = self.categorize_epic(epic_data)
-            
-            # Build calculated fields
-            calculated_fields = CalculatedFields(
-                planned_start_date=calculated_dates.planned_start_date.isoformat(),
-                planned_end_date=calculated_dates.planned_end_date.isoformat(),
-                calculated_duration_days=calculated_dates.calculated_duration_days,
-                duration_unit=calculated_dates.duration_unit,
-                business_days_used=calculated_dates.business_days_used,
-                calculation_notes=calculated_dates.calculation_notes,
-                
-                total_tasks=tasks_analysis['total_tasks'],
-                tdd_tasks=tasks_analysis['tdd_tasks'],
-                analysis_tasks=tasks_analysis['analysis_tasks'],
-                estimated_total_minutes=tasks_analysis['estimated_total_minutes'],
-                estimated_total_hours=tasks_analysis['estimated_total_hours'],
-                
-                labels_count=len(epic_data.get('labels', [])),
-                goals_count=len(epic_data.get('goals', [])),
-                definition_of_done_count=len(epic_data.get('definition_of_done', [])),
-                
-                task_phases=tasks_analysis['task_phases'],
-                epic_category=category,
-                complexity_score=complexity
-            )
-            
-            # Build metadata
-            metadata = EnrichmentMetadata(
-                version="v1.0",
-                calculation_strategy=self.base_strategy.value,
-                source_file=source_file
-            )
-            
-            # Return enriched epic (original + calculated + metadata)
-            enriched = {
-                **epic_data,  # Original data preserved
-                'calculated_fields': asdict(calculated_fields),
-                'metadata': asdict(metadata)
-            }
-            
-            return enriched
-            
+            dates = self.calculator.calculate_epic_dates(epic, reference_date)
+            calc.planned_start_date = dates.planned_start_date.isoformat()
+            calc.planned_end_date = dates.planned_end_date.isoformat()
+            calc.calculated_duration_days = int(dates.calculated_duration_days)
         except Exception as e:
-            # Return original data with error metadata
-            error_metadata = EnrichmentMetadata(
-                source_file=source_file,
-                errors=[f"Enrichment failed: {str(e)}"]
-            )
-            
-            return {
-                **epic_data,
-                'calculated_fields': asdict(CalculatedFields()),
-                'metadata': asdict(error_metadata)
-            }
-    
-    def enrich_epic_file(self, file_path: Path, output_path: Optional[Path] = None) -> Dict[str, Any]:
-        """
-        Enrich epic from JSON file.
-        
-        Args:
-            file_path: Path to input JSON file
-            output_path: Path to save enriched JSON (optional)
-            
-        Returns:
-            Enriched epic data
-        """
+            meta.errors.append(f"date_calc: {e}")
         try:
-            # Load original JSON
-            with open(file_path, 'r', encoding='utf-8') as f:
-                original_data = json.load(f)
-            
-            # Extract epic data (handle nested structure)
-            if 'epic' in original_data:
-                epic_data = original_data['epic'] 
-                wrapper = original_data
-            else:
-                epic_data = original_data
-                wrapper = None
-            
-            # Enrich epic
-            enriched_epic = self.enrich_epic(epic_data, str(file_path))
-            
-            # Rebuild structure if was nested
-            if wrapper:
-                result = {
-                    **wrapper,
-                    'epic': enriched_epic
-                }
-            else:
-                result = enriched_epic
-            
-            # Save if output path provided
-            if output_path:
-                with open(output_path, 'w', encoding='utf-8') as f:
-                    json.dump(result, f, indent=2, ensure_ascii=False)
-                print(f"‚úÖ Enriched epic saved to {output_path}")
-            
-            return result
-            
+            calc.epic_category = self.categorize_epic(epic)
+            calc.complexity_score = self.compute_complexity(epic)
         except Exception as e:
-            print(f"‚ùå Error enriching {file_path}: {e}")
-            traceback.print_exc()
-            return {}
-    
-    def enrich_all_epics(self, epics_dir: Path, output_dir: Optional[Path] = None) -> List[Dict[str, Any]]:
-        """
-        Enrich all epic files in a directory.
-        
-        Args:
-            epics_dir: Directory containing epic JSON files
-            output_dir: Directory to save enriched files (optional)
-            
-        Returns:
-            List of enriched epics
-        """
-        enriched_epics = []
-        
-        # Find all JSON files
-        json_files = list(epics_dir.glob('*.json'))
-        
-        if not json_files:
-            print(f"‚ö†Ô∏è No JSON files found in {epics_dir}")
-            return []
-        
-        print(f"üîç Found {len(json_files)} epic files to enrich")
-        
-        for file_path in json_files:
-            print(f"üìÑ Processing {file_path.name}...")
-            
-            # Determine output path
-            if output_dir:
-                output_dir.mkdir(exist_ok=True)
-                output_path = output_dir / f"enriched_{file_path.name}"
-            else:
-                output_path = None
-            
-            # Enrich epic
-            enriched = self.enrich_epic_file(file_path, output_path)
-            if enriched:
-                enriched_epics.append(enriched)
-        
-        print(f"‚úÖ Enriched {len(enriched_epics)} epics successfully")
-        return enriched_epics
-
+            meta.errors.append(f"categorization: {e}")
+        return {
+            "epic": epic,
+            "calculated_fields": asdict(calc),
+            "metadata": asdict(meta),
+        }
 
-def main():
-    """Main function to test JSON enrichment."""
-    print("‚ú® JSON Enrichment Engine Test")
-    print("=" * 60)
-    
-    # Test with single epic
-    epics_dir = Path("epics/user_epics")
-    if not epics_dir.exists():
-        print(f"‚ùå Directory {epics_dir} not found")
-        return
-    
-    # Initialize engine
-    engine = JSONEnrichmentEngine(DateBaseStrategy.NEXT_MONDAY)
-    
-    # Test with epico_0.json
-    test_file = epics_dir / "epico_0.json"
-    if test_file.exists():
-        print(f"üß™ Testing with {test_file.name}")
-        enriched = engine.enrich_epic_file(test_file)
-        
-        if enriched:
-            # Show enrichment results
-            if 'epic' in enriched:
-                calc_fields = enriched['epic'].get('calculated_fields', {})
-                metadata = enriched['epic'].get('metadata', {})
-            else:
-                calc_fields = enriched.get('calculated_fields', {})
-                metadata = enriched.get('metadata', {})
-            
-            print("\\nüìä Enrichment Results:")
-            print(f"   Planned Start: {calc_fields.get('planned_start_date')}")
-            print(f"   Planned End: {calc_fields.get('planned_end_date')}")
-            print(f"   Duration: {calc_fields.get('calculated_duration_days')} days")
-            print(f"   Total Tasks: {calc_fields.get('total_tasks')}")
-            print(f"   TDD Tasks: {calc_fields.get('tdd_tasks')}")
-            print(f"   Category: {calc_fields.get('epic_category')}")
-            print(f"   Complexity: {calc_fields.get('complexity_score')}/10")
-            print(f"   Strategy: {metadata.get('calculation_strategy')}")
-    
-    # Test enriching all epics
-    print("\\nüîÑ Testing batch enrichment...")
-    output_dir = Path("epics/enriched")
-    enriched_epics = engine.enrich_all_epics(epics_dir, output_dir)
-    
-    print(f"\\n‚úÖ JSON Enrichment Engine working correctly!")
-    print(f"Enriched {len(enriched_epics)} epics total")
+    def enrich_file(self, path: Path, reference_date: Optional[date] = None) -> Dict[str, Any]:
+        epic = json.loads(Path(path).read_text(encoding='utf-8'))
+        epic["_source"] = str(path)
+        return self.enrich_epic(epic, reference_date)
+
+    def enrich_all(self, input_dir: Path, output_dir: Optional[Path] = None
+                   ) -> List[Dict[str, Any]]:
+        output: List[Dict[str, Any]] = []
+        for p in sorted(Path(input_dir).glob("*.json")):
+            enriched = self.enrich_file(p)
+            output.append(enriched)
+            if output_dir:
+                output_dir.mkdir(parents=True, exist_ok=True)
+                out_path = output_dir / p.name
+                out_path.write_text(json.dumps(enriched, ensure_ascii=False, indent=2), encoding='utf-8')
+        return output
 
 
 if __name__ == "__main__":
-    main()
\ No newline at end of file
+    engine = JsonEnrichmentEngine()
+    sample = {"name": "Environment & Production Safety", "duration": "2 dias", "labels": ["infra", "safety"]}
+    print(json.dumps(engine.enrich_epic(sample), ensure_ascii=False, indent=2))
 
EOF
)