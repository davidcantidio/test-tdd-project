#!/bin/bash
# üß† AUDIT SCRIPT INTELIGENTE - Auditoria Extensiva com Real LLM Analysis
# 
# Baseado na infraestrutura de agentes inteligentes testada e validada
# Realiza auditoria sem√¢ntica profunda de todo o projeto

set -euo pipefail
shopt -s lastpipe
export LC_ALL=C.UTF-8
umask 077

## -------------------------
## Flags & helpers
## -------------------------
VERBOSE=0
KEEP=0
LIMIT=""

usage() {
  cat <<'USAGE'
Uso: ./audit_intelligent.sh [op√ß√µes]
  --verbose          Liga modo verboso (set -x)
  --keep             N√£o apaga .audit_intelligent antes de rodar
  --limit N          Limita a an√°lise a N arquivos priorit√°rios (propagado aos blocos python)
  -h|--help          Mostra esta ajuda
USAGE
}

die() { echo "‚ùå ERRO: $*" >&2; exit 1; }
info(){ printf '%s\n' "$*"; }

on_err() {
  local lineno=$1
  echo "üí• Falha na linha ${lineno}. Consulte os artefatos em ${AUDIT_DIR}/ (se j√° criados)." >&2
}
trap 'on_err $LINENO' ERR
set -o errtrace

while [[ $# -gt 0 ]]; do
  case "$1" in
    --verbose) VERBOSE=1; shift ;;
    --keep)    KEEP=1;    shift ;;
    --limit)   LIMIT="${2:-}"; [[ -n "${LIMIT}" ]] || die "--limit requer um valor"; shift 2 ;;
    -h|--help) usage; exit 0 ;;
    *) die "Op√ß√£o inv√°lida: $1";;
  esac
done

if [[ ${VERBOSE} -eq 1 ]]; then
  set -x
fi

command -v python3 >/dev/null 2>&1 || die "python3 n√£o encontrado no PATH"

# Configura√ß√£o
AUDIT_DIR=".audit_intelligent"
PROJECT_ROOT="."
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
REPORT_FILE="${AUDIT_DIR}/intelligent_audit_report_${TIMESTAMP}.md"

run_step() {
  # Uso: run_step "Descri√ß√£o" comando...
  local desc="$1"; shift
  info "‚ñ∂Ô∏è  ${desc}"
  "$@"
  local rc=$?
  info "‚úÖ ${desc} (rc=${rc})"
}

echo "üß† Iniciando AUDITORIA INTELIGENTE EXTENSIVA‚Ä¶"
echo "üìÖ Timestamp: ${TIMESTAMP}"

# Limpar e criar diret√≥rio de auditoria
if [[ ${KEEP} -eq 0 ]]; then
  # Defesa adicional: garanta que a var n√£o est√° vazia
  [[ -n "${AUDIT_DIR}" && "${AUDIT_DIR}" != "/" ]] || die "AUDIT_DIR inv√°lido"
  rm -rf -- "${AUDIT_DIR}"
fi
mkdir -p -- "${AUDIT_DIR}"/{reports,analysis,recommendations,performance}

# Registrar meta-informa√ß√µes da execu√ß√£o
{
  echo "timestamp=${TIMESTAMP}"
  echo "project_root=${PROJECT_ROOT}"
  echo "keep=${KEEP}"
  echo "limit=${LIMIT}"
  python3 --version 2>&1 | sed 's/^/python_version=/'
} > "${AUDIT_DIR}/run.meta"

# Banner de in√≠cio
cat > "${REPORT_FILE}" << 'EOF'
# üß† RELAT√ìRIO DE AUDITORIA INTELIGENTE

**Sistema:** test-tdd-project Enterprise Framework  
**Tipo:** Auditoria Extensiva com Real LLM Analysis  
**Data:** $(date)  
**Agentes:** 5 agentes inteligentes + context integration  

---

## üìä EXECUTIVE SUMMARY

EOF

# Helper para injetar LIMIT para os blocos Python (via vari√°vel de ambiente)
export AI_AUDIT_LIMIT="${LIMIT}"

# Pequeno wrapper para rodar blocos Python com padroniza√ß√£o de log
pyblock() { python3 - "$@"; }

## Exemplo de uso uniformizado
## run_step "Fase 1: Invent√°rio Completo do Sistema" \
##   pyblock <<'EOF'
##   # c√≥digo python‚Ä¶
## EOF

echo "üìä Executando an√°lise de invent√°rio completo..."

# 1. INVENT√ÅRIO COMPLETO DO PROJETO
echo "üîç Fase 1: Invent√°rio Completo do Sistema"
python3 - << 'EOF'
import pathlib
import json
from collections import defaultdict

PROJECT_ROOT = pathlib.Path(".")
AUDIT_DIR = pathlib.Path(".audit_intelligent")

# Coletar todos os arquivos Python
py_files = []
modules = defaultdict(list)

for py_file in PROJECT_ROOT.rglob("*.py"):
    if any(skip in str(py_file) for skip in ['.git', '__pycache__', '.pytest_cache', 'venv', '.venv']):
        continue
    
    py_files.append(str(py_file))
    
    # Categorizar por m√≥dulo principal
    parts = py_file.parts
    if len(parts) > 1:
        main_module = parts[0]
        modules[main_module].append(str(py_file))
    else:
        modules["root"].append(str(py_file))

# Estat√≠sticas
total_files = len(py_files)
total_lines = 0
total_size = 0

file_stats = []
for py_file in py_files:
    try:
        with open(py_file, 'r', encoding='utf-8') as f:
            lines = len(f.readlines())
        size = pathlib.Path(py_file).stat().st_size
        total_lines += lines
        total_size += size
        
        file_stats.append({
            "file": py_file,
            "lines": lines,
            "size": size,
            "module": py_file.split('/')[0] if '/' in py_file else 'root'
        })
    except Exception as e:
        print(f"‚ö†Ô∏è Erro lendo {py_file}: {e}")

# Salvar invent√°rio
inventory = {
    "total_files": total_files,
    "total_lines": total_lines,
    "total_size_bytes": total_size,
    "modules": dict(modules),
    "file_details": file_stats,
    "module_summary": {module: len(files) for module, files in modules.items()}
}

with open(AUDIT_DIR / "inventory.json", "w") as f:
    json.dump(inventory, f, indent=2)

print(f"üìÅ Total arquivos Python: {total_files}")
print(f"üìù Total linhas: {total_lines:,}")
print(f"üíæ Total tamanho: {total_size/1024/1024:.2f} MB")
print(f"üèóÔ∏è M√≥dulos encontrados: {list(modules.keys())}")
EOF

# 2. AN√ÅLISE COM AGENTES INTELIGENTES
echo "üß† Fase 2: An√°lise com Agentes Inteligentes"

# Criar lista de arquivos priorit√°rios para an√°lise LLM
python3 - << 'EOF'
import json
import pathlib

AUDIT_DIR = pathlib.Path(".audit_intelligent")

# Carregar invent√°rio
with open(AUDIT_DIR / "inventory.json") as f:
    inventory = json.load(f)

# Priorizar arquivos por tamanho e import√¢ncia
priority_files = []

# PRIORIZA√á√ÉO INTELIGENTE PARA AN√ÅLISE SEM√ÇNTICA REAL
# Ignorar __init__.py pequenos (pouco c√≥digo para analisar)
substantial_files = [f for f in inventory["file_details"] if f["lines"] > 10 and not f["file"].endswith("__init__.py")]

# Arquivos principais (sempre analisar)
main_files = [f for f in substantial_files if any(keyword in f["file"] for keyword in [
    "streamlit_app.py", "main.py", "app.py"
])]

# Arquivos grandes (poss√≠veis God Codes) - PRIORIDADE M√ÅXIMA para an√°lise sem√¢ntica
large_files = [f for f in substantial_files if f["lines"] > 300]

# Arquivos core com c√≥digo substancial
core_files = [f for f in substantial_files if any(keyword in f["file"] for keyword in [
    "service", "manager", "database", "auth", "security", "config"
]) and f["lines"] > 50]

# Arquivos de agentes inteligentes (para validar nossa transforma√ß√£o)
agent_files = [f for f in substantial_files if "agent" in f["file"] and f["lines"] > 100]

# Arquivos utils com complexidade
utils_files = [f for f in substantial_files if "utils" in f["file"] and f["lines"] > 100]

# Combinar por prioridade: grandes -> agentes -> core -> main -> utils
all_priority = large_files + agent_files + core_files + main_files + utils_files
seen = set()
unique_priority = []
for f in all_priority:
    if f["file"] not in seen:
        unique_priority.append(f["file"])
        seen.add(f["file"])

# Aumentar para 35 arquivos mais importantes (mais an√°lise sem√¢ntica)
priority_files = unique_priority[:35]

with open(AUDIT_DIR / "priority_files.txt", "w") as f:
    for file_path in priority_files:
        f.write(f"{file_path}\n")

print(f"üéØ Arquivos priorit√°rios selecionados: {len(priority_files)}")
for i, file_path in enumerate(priority_files[:5], 1):
    print(f"  {i}. {file_path}")
if len(priority_files) > 5:
    print(f"  ... e mais {len(priority_files) - 5} arquivos")
EOF

echo "üîç Executando an√°lise com IntelligentCodeAgent..."

# An√°lise detalhada com agente inteligente
python3 - << 'EOF'
import sys
import json
import pathlib
import time
from datetime import datetime

sys.path.append('.')

try:
    from audit_system.agents.intelligent_code_agent import IntelligentCodeAgent, AnalysisDepth, SemanticMode
    
    AUDIT_DIR = pathlib.Path(".audit_intelligent")
    
    # Carregar arquivos priorit√°rios
    with open(AUDIT_DIR / "priority_files.txt") as f:
        priority_files = [line.strip() for line in f if line.strip()]
    
    # Inicializar agente com an√°lise sem√¢ntica real
    agent = IntelligentCodeAgent(
        project_root=pathlib.Path("."),
        enable_real_llm=True,  # ATIVAR an√°lise sem√¢ntica real (n√£o pattern-based)
        analysis_depth=AnalysisDepth.DEEP,  # An√°lise profunda para m√°xima detec√ß√£o
        semantic_mode=SemanticMode.AGGRESSIVE  # Modo agressivo para encontrar mais issues
    )
    
    print(f"üöÄ AN√ÅLISE SEM√ÇNTICA REAL ATIVADA:")
    print(f"   ‚Ä¢ Modo: DEEP + AGGRESSIVE (an√°lise completa)")
    print(f"   ‚Ä¢ Arquivos priorizados: {len(priority_files)} (c√≥digo substancial)")
    print(f"   ‚Ä¢ Capacidades: God Code detection, Security analysis, Refactoring suggestions")
    print(f"üß† Iniciando an√°lise inteligente...")
    
    analysis_results = []
    total_issues = 0
    total_recommendations = 0
    
    for i, file_path in enumerate(priority_files, 1):
        try:
            print(f"  [{i}/{len(priority_files)}] {file_path}")
            
            start_time = time.time()
            analysis = agent.analyze_file_intelligently(file_path)
            duration = time.time() - start_time
            
            file_result = {
                "file_path": file_path,
                "analysis_duration": duration,
                "lines_analyzed": len(analysis.lines_analyzed),
                "architectural_role": analysis.architectural_role,
                "semantic_quality_score": analysis.semantic_quality_score,
                "testability_score": analysis.testability_score,
                "security_vulnerabilities_count": len(analysis.security_vulnerabilities),
                "complexity_hotspots_count": len(analysis.complexity_hotspots),
                "performance_bottlenecks_count": len(analysis.performance_bottlenecks),
                "recommended_refactorings_count": len(analysis.recommended_refactorings),
                "tokens_used": analysis.tokens_used
            }
            
            analysis_results.append(file_result)
            total_issues += (len(analysis.security_vulnerabilities) + 
                           len(analysis.complexity_hotspots) + 
                           len(analysis.performance_bottlenecks))
            total_recommendations += len(analysis.recommended_refactorings)
            
        except Exception as e:
            print(f"    ‚ùå Erro analisando {file_path}: {e}")
            analysis_results.append({
                "file_path": file_path,
                "error": str(e),
                "analysis_duration": 0
            })
    
    # Salvar resultados
    analysis_summary = {
        "timestamp": datetime.now().isoformat(),
        "files_analyzed": len(priority_files),
        "successful_analyses": len([r for r in analysis_results if "error" not in r]),
        "total_issues_found": total_issues,
        "total_recommendations": total_recommendations,
        "results": analysis_results
    }
    
    with open(AUDIT_DIR / "intelligent_analysis.json", "w") as f:
        json.dump(analysis_summary, f, indent=2)
    
    print(f"‚úÖ An√°lise conclu√≠da:")
    print(f"   üìÅ Arquivos analisados: {analysis_summary['files_analyzed']}")
    print(f"   ‚úÖ An√°lises bem-sucedidas: {analysis_summary['successful_analyses']}")
    print(f"   üö® Total de issues: {total_issues}")
    print(f"   üîß Total de recomenda√ß√µes: {total_recommendations}")

except ImportError as e:
    print(f"‚ùå Erro importando agentes: {e}")
    print("üìã Usando an√°lise b√°sica como fallback...")
    
    # Fallback para an√°lise b√°sica
    fallback_results = {
        "timestamp": datetime.now().isoformat(),
        "mode": "fallback_basic_analysis",
        "message": "Agentes inteligentes n√£o dispon√≠veis - an√°lise b√°sica executada"
    }
    
    with open(AUDIT_DIR / "intelligent_analysis.json", "w") as f:
        json.dump(fallback_results, f, indent=2)
EOF

# 3. AN√ÅLISE DE DEPEND√äNCIAS E √ìRF√ÉOS
echo "üîó Fase 3: An√°lise de Depend√™ncias"
python3 - << 'EOF'
import ast
import pathlib
import json
from collections import defaultdict, Counter

AUDIT_DIR = pathlib.Path(".audit_intelligent")

# An√°lise de imports e depend√™ncias
import_graph = []
all_modules = set()
internal_imports = defaultdict(list)
external_imports = defaultdict(list)
orphan_files = []

# Coletar todos os arquivos Python
py_files = []
for py_file in pathlib.Path(".").rglob("*.py"):
    if any(skip in str(py_file) for skip in ['.git', '__pycache__', '.pytest_cache']):
        continue
    py_files.append(py_file)

print(f"üîç Analisando depend√™ncias em {len(py_files)} arquivos...")

# An√°lise de imports
imported_files = set()
for py_file in py_files:
    try:
        content = py_file.read_text(encoding="utf-8", errors="ignore")
        tree = ast.parse(content)
        
        file_imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    import_name = alias.name
                    file_imports.append(import_name)
                    
                    if any(internal in import_name for internal in ['streamlit_extension', 'audit_system', 'duration_system']):
                        internal_imports[str(py_file)].append(import_name)
                        imported_files.add(import_name)
                    else:
                        external_imports[str(py_file)].append(import_name)
            
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    file_imports.append(node.module)
                    if any(internal in node.module for internal in ['streamlit_extension', 'audit_system', 'duration_system']):
                        internal_imports[str(py_file)].append(node.module)
                        imported_files.add(node.module)
                    else:
                        external_imports[str(py_file)].append(node.module)
        
        import_graph.append({
            "file": str(py_file),
            "imports": file_imports,
            "internal_count": len(internal_imports[str(py_file)]),
            "external_count": len(external_imports[str(py_file)])
        })
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro analisando {py_file}: {e}")

# Identificar √≥rf√£os (arquivos nunca importados)
all_py_modules = set()
for py_file in py_files:
    # Converter caminho para nome de m√≥dulo
    rel_path = py_file.relative_to(pathlib.Path("."))
    if py_file.name == "__init__.py":
        module_name = str(rel_path.parent).replace("/", ".")
    else:
        module_name = str(rel_path.with_suffix("")).replace("/", ".")
    all_py_modules.add(module_name)

# √ìrf√£os s√£o m√≥dulos que existem mas nunca s√£o importados
potential_orphans = all_py_modules - imported_files

# An√°lise de depend√™ncias externas mais comuns
all_external = []
for imports in external_imports.values():
    all_external.extend(imports)

external_counter = Counter(all_external)

# Salvar an√°lise de depend√™ncias
dependency_analysis = {
    "total_files": len(py_files),
    "files_with_imports": len([f for f in import_graph if f["imports"]]),
    "total_internal_imports": sum(len(imports) for imports in internal_imports.values()),
    "total_external_imports": sum(len(imports) for imports in external_imports.values()),
    "potential_orphans": list(potential_orphans),
    "orphan_count": len(potential_orphans),
    "top_external_dependencies": dict(external_counter.most_common(10)),
    "import_graph": import_graph
}

with open(AUDIT_DIR / "dependency_analysis.json", "w") as f:
    json.dump(dependency_analysis, f, indent=2)

print(f"‚úÖ An√°lise de depend√™ncias:")
print(f"   üì¶ Arquivos com imports: {dependency_analysis['files_with_imports']}")
print(f"   üîó Imports internos: {dependency_analysis['total_internal_imports']}")
print(f"   üåê Imports externos: {dependency_analysis['total_external_imports']}")
print(f"   üèùÔ∏è Poss√≠veis √≥rf√£os: {dependency_analysis['orphan_count']}")
EOF

# 4. GERAR RELAT√ìRIO FINAL
echo "üìã Fase 4: Gerando Relat√≥rio Final"
python3 - << 'EOF'
import json
import pathlib
from datetime import datetime

AUDIT_DIR = pathlib.Path(".audit_intelligent")
REPORT_FILE = AUDIT_DIR / f"intelligent_audit_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

# Carregar dados
try:
    with open(AUDIT_DIR / "inventory.json") as f:
        inventory = json.load(f)
except:
    inventory = {"total_files": 0, "total_lines": 0, "modules": {}}

try:
    with open(AUDIT_DIR / "intelligent_analysis.json") as f:
        analysis = json.load(f)
except:
    analysis = {"files_analyzed": 0, "total_issues_found": 0, "total_recommendations": 0}

try:
    with open(AUDIT_DIR / "dependency_analysis.json") as f:
        dependencies = json.load(f)
except:
    dependencies = {"orphan_count": 0, "total_external_imports": 0}

# Gerar relat√≥rio
report_content = f"""# üß† RELAT√ìRIO DE AUDITORIA INTELIGENTE

**Sistema:** test-tdd-project Enterprise Framework  
**Tipo:** Auditoria Extensiva com Real LLM Analysis  
**Data:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Agentes:** Intelligent Code Agent + Dependency Analysis  

---

## üìä EXECUTIVE SUMMARY

### üéØ **RESULTADOS PRINCIPAIS**
- **Total de Arquivos:** {inventory.get('total_files', 0):,} arquivos Python
- **Total de Linhas:** {inventory.get('total_lines', 0):,} linhas de c√≥digo
- **Issues Identificados:** {analysis.get('total_issues_found', 0)} problemas encontrados
- **Recomenda√ß√µes:** {analysis.get('total_recommendations', 0)} melhorias sugeridas
- **Arquivos √ìrf√£os:** {dependencies.get('orphan_count', 0)} arquivos n√£o utilizados

### üèóÔ∏è **M√ìDULOS ANALISADOS**
"""

for module, count in inventory.get('module_summary', {}).items():
    report_content += f"- **{module}:** {count} arquivos\n"

report_content += f"""

### üö® **AN√ÅLISE DE QUALIDADE**
- **Arquivos Analisados:** {analysis.get('files_analyzed', 0)}
- **An√°lises Bem-sucedidas:** {analysis.get('successful_analyses', 0)}
- **Taxa de Sucesso:** {(analysis.get('successful_analyses', 0) / max(analysis.get('files_analyzed', 1), 1) * 100):.1f}%

### üîó **AN√ÅLISE DE DEPEND√äNCIAS**
- **Dependencies Externas:** {dependencies.get('total_external_imports', 0)}
- **Arquivos √ìrf√£os:** {dependencies.get('orphan_count', 0)}

---

## üéØ **RECOMENDA√á√ïES PRIORIT√ÅRIAS**

### 1. **Issues de Qualidade**
"""

if analysis.get('total_issues_found', 0) > 0:
    report_content += f"- Foram encontrados {analysis.get('total_issues_found', 0)} issues que precisam de aten√ß√£o\n"
    report_content += "- Recomenda-se revisar arquivos com maior n√∫mero de problemas\n"
else:
    report_content += "- ‚úÖ Nenhum issue cr√≠tico identificado\n"

if dependencies.get('orphan_count', 0) > 0:
    report_content += f"""
### 2. **Limpeza de C√≥digo**
- {dependencies.get('orphan_count', 0)} arquivos √≥rf√£os identificados
- Considerar remo√ß√£o ap√≥s valida√ß√£o manual
"""

report_content += f"""

### 3. **Pr√≥ximos Passos**
1. **Revisar Issues Cr√≠ticos:** Focar nos arquivos com maior n√∫mero de problemas
2. **Implementar Recomenda√ß√µes:** Aplicar as {analysis.get('total_recommendations', 0)} melhorias sugeridas
3. **Limpeza de C√≥digo:** Remover arquivos √≥rf√£os ap√≥s valida√ß√£o
4. **Monitoramento Cont√≠nuo:** Executar auditoria regular com agentes inteligentes

---

## üìã **DETALHES T√âCNICOS**

### **Metodologia**
- **Invent√°rio Completo:** An√°lise de todos os arquivos Python do projeto
- **An√°lise Inteligente:** Uso de agentes IA para an√°lise sem√¢ntica
- **An√°lise de Depend√™ncias:** Mapeamento completo de imports e depend√™ncias
- **Categoriza√ß√£o de Seguran√ßa:** Classifica√ß√£o de arquivos por risco de remo√ß√£o

### **Ferramentas Utilizadas**
- **IntelligentCodeAgent:** An√°lise sem√¢ntica avan√ßada
- **AST Parser:** An√°lise sint√°tica de depend√™ncias
- **Pattern Matching:** Identifica√ß√£o de anti-patterns

---

*Relat√≥rio gerado automaticamente pela Auditoria Inteligente em {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

# Salvar relat√≥rio
with open(REPORT_FILE, "w", encoding="utf-8") as f:
    f.write(report_content)

print(f"üìã Relat√≥rio final gerado: {REPORT_FILE}")
print(f"üìÅ Todos os arquivos salvos em: {AUDIT_DIR}")
EOF

echo ""
echo "üéâ AUDITORIA INTELIGENTE CONCLU√çDA!"
echo "üìã Relat√≥rio dispon√≠vel em: ${AUDIT_DIR}/"
echo "üîç Execute 'ls ${AUDIT_DIR}/' para ver todos os arquivos gerados"
echo ""
echo "üìä Pr√≥ximos passos recomendados:"
echo "   1. Revisar o relat√≥rio principal"
echo "   2. Analisar arquivos com mais issues"
echo "   3. Implementar recomenda√ß√µes priorit√°rias"
echo "   4. Considerar remo√ß√£o de √≥rf√£os (com cuidado)"