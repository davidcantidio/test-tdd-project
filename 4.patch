 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/streamlit_extension/middleware/__init__.py b/streamlit_extension/middleware/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..6e4f349ec9e1b44e230bd6b8410529adfce029d3
--- /dev/null
+++ b/streamlit_extension/middleware/__init__.py
@@ -0,0 +1 @@
+"""Middleware utilities for correlation and context management."""
diff --git a/streamlit_extension/middleware/context_manager.py b/streamlit_extension/middleware/context_manager.py
new file mode 100644
index 0000000000000000000000000000000000000000..51eda2ddd4bed47f5afbdfec841dd4f850f35bf5
--- /dev/null
+++ b/streamlit_extension/middleware/context_manager.py
@@ -0,0 +1,108 @@
+"""User context preservation utilities."""
+
+from __future__ import annotations
+
+import threading
+import uuid
+from dataclasses import dataclass
+from datetime import datetime
+from typing import Any, Dict, List, Optional
+
+from .correlation import CorrelationManager, RequestLifecycleTracker
+
+
+@dataclass
+class UserContext:
+    """Dataclass representing user-related context information."""
+
+    user_id: Optional[str]
+    session_id: str
+    request_id: str
+    correlation_id: str
+    ip_address: str
+    user_agent: str
+    timestamp: datetime
+    permissions: List[str]
+    preferences: Dict[str, Any]
+    performance_budget: Dict[str, float]
+
+    def to_dict(self) -> Dict[str, Any]:
+        return {
+            "user_id": self.user_id,
+            "session_id": self.session_id,
+            "request_id": self.request_id,
+            "correlation_id": self.correlation_id,
+            "ip_address": self.ip_address,
+            "user_agent": self.user_agent,
+            "timestamp": self.timestamp.isoformat(),
+            "permissions": self.permissions,
+            "preferences": self.preferences,
+            "performance_budget": self.performance_budget,
+        }
+
+    def sanitize_for_logging(self) -> Dict[str, Any]:
+        data = self.to_dict()
+        data.pop("preferences", None)
+        return data
+
+
+class ContextManager:
+    """Handle building and retrieving :class:`UserContext` objects."""
+
+    def __init__(self, correlation_manager: Optional[CorrelationManager] = None) -> None:
+        self.correlation_manager = correlation_manager or CorrelationManager()
+        self.local = threading.local()
+
+    def build_context(self, request_data: Dict[str, Any]) -> UserContext:
+        correlation_id = self.correlation_manager.get_or_create()
+        context = UserContext(
+            user_id=request_data.get("user_id"),
+            session_id=request_data.get("session_id", str(uuid.uuid4())),
+            request_id=request_data.get("request_id", str(uuid.uuid4())),
+            correlation_id=correlation_id,
+            ip_address=request_data.get("ip_address", "0.0.0.0"),
+            user_agent=request_data.get("user_agent", "unknown"),
+            timestamp=datetime.now(),
+            permissions=request_data.get("permissions", []),
+            preferences=request_data.get("preferences", {}),
+            performance_budget=request_data.get("performance_budget", {}),
+        )
+        self.local.context = context
+        return context
+
+    def get_context(self) -> Optional[UserContext]:
+        return getattr(self.local, "context", None)
+
+    def clear_context(self) -> None:
+        if hasattr(self.local, "context"):
+            del self.local.context
+        # Also clear correlation ID for new requests
+        self.correlation_manager.clear_correlation_id()
+
+
+class ContextMiddleware:
+    """Simple middleware to manage user context and correlation IDs."""
+
+    def __init__(
+        self,
+        context_manager: Optional[ContextManager] = None,
+        lifecycle_tracker: Optional[RequestLifecycleTracker] = None,
+    ) -> None:
+        self.context_manager = context_manager or ContextManager()
+        self.lifecycle_tracker = lifecycle_tracker or RequestLifecycleTracker()
+
+    def process_request(self, request: Dict[str, Any]) -> UserContext:
+        context = self.context_manager.build_context(request)
+        self.lifecycle_tracker.track_request_start(context.correlation_id, context.to_dict())
+        return context
+
+    def process_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
+        context = self.context_manager.get_context()
+        if context:
+            headers = response.setdefault("headers", {})
+            headers["X-Correlation-ID"] = context.correlation_id
+            self.lifecycle_tracker.track_request_end(
+                context.correlation_id, response.get("status", "ok")
+            )
+            self.context_manager.clear_context()
+        return response
diff --git a/streamlit_extension/middleware/correlation.py b/streamlit_extension/middleware/correlation.py
new file mode 100644
index 0000000000000000000000000000000000000000..8ca09b2db9fae861067adf43fe87eda05e32fb37
--- /dev/null
+++ b/streamlit_extension/middleware/correlation.py
@@ -0,0 +1,55 @@
+"""Correlation ID management and request lifecycle tracking."""
+
+from __future__ import annotations
+
+import threading
+import time
+import uuid
+from typing import Dict, List, Optional, Tuple
+
+
+class CorrelationManager:
+    """Manage correlation IDs using thread-local storage."""
+
+    def __init__(self) -> None:
+        self.correlation_context = threading.local()
+
+    def generate_correlation_id(self) -> str:
+        """Generate unique correlation ID."""
+        return f"{uuid.uuid4().hex[:8]}-{int(time.time())}"
+
+    def set_correlation_id(self, correlation_id: str) -> None:
+        """Set correlation ID for current thread."""
+        self.correlation_context.id = correlation_id
+
+    def get_correlation_id(self) -> Optional[str]:
+        """Get current correlation ID."""
+        return getattr(self.correlation_context, "id", None)
+
+    def get_or_create(self) -> str:
+        """Return existing correlation ID or create a new one."""
+        cid = self.get_correlation_id()
+        if cid is None:
+            cid = self.generate_correlation_id()
+            self.set_correlation_id(cid)
+        return cid
+
+    def clear_correlation_id(self) -> None:
+        """Clear correlation ID from current thread."""
+        if hasattr(self.correlation_context, "id"):
+            del self.correlation_context.id
+
+
+class RequestLifecycleTracker:
+    """Track request lifecycle events for debugging and analytics."""
+
+    def __init__(self) -> None:
+        self.events: List[Tuple[str, str, Dict]] = []
+
+    def track_request_start(self, correlation_id: str, context: Dict) -> None:
+        """Record the start of a request."""
+        self.events.append(("start", correlation_id, context))
+
+    def track_request_end(self, correlation_id: str, status: str) -> None:
+        """Record the end of a request."""
+        self.events.append(("end", correlation_id, {"status": status}))
diff --git a/streamlit_extension/middleware/error_correlation.py b/streamlit_extension/middleware/error_correlation.py
new file mode 100644
index 0000000000000000000000000000000000000000..fb21d6471bd8e32e3752db559d490567524be731
--- /dev/null
+++ b/streamlit_extension/middleware/error_correlation.py
@@ -0,0 +1,76 @@
+"""Error correlation and pattern analysis helpers."""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime, timedelta
+from typing import Dict, List
+
+
+@dataclass
+class ErrorEvent:
+    timestamp: datetime
+    message: str
+
+
+@dataclass
+class ErrorPattern:
+    pattern_type: str
+    frequency: int
+    time_span: timedelta
+    root_cause: str
+    impact_scope: int
+
+
+class ErrorPatternAnalyzer:
+    """Analyze error patterns based on correlation IDs."""
+
+    def __init__(self) -> None:
+        self.error_store: Dict[str, List[ErrorEvent]] = {}
+
+    def record_error(self, correlation_id: str, event: ErrorEvent) -> None:
+        self.error_store.setdefault(correlation_id, []).append(event)
+
+    def get_correlated_errors(self, correlation_id: str) -> List[ErrorEvent]:
+        return self.error_store.get(correlation_id, [])
+
+    def detect_pattern_type(self, related_errors: List[ErrorEvent]) -> str:
+        return "repeated" if len(related_errors) > 1 else "single"
+
+    def calculate_time_span(self, related_errors: List[ErrorEvent]) -> timedelta:
+        if len(related_errors) < 2:
+            return timedelta(0)
+        return related_errors[-1].timestamp - related_errors[0].timestamp
+
+    def identify_root_cause(self, related_errors: List[ErrorEvent]) -> str:
+        return related_errors[0].message if related_errors else ""
+
+    def calculate_impact(self, related_errors: List[ErrorEvent]) -> int:
+        return len(related_errors)
+
+    def analyze_error_patterns(self, correlation_id: str) -> ErrorPattern:
+        related_errors = self.get_correlated_errors(correlation_id)
+        return ErrorPattern(
+            pattern_type=self.detect_pattern_type(related_errors),
+            frequency=len(related_errors),
+            time_span=self.calculate_time_span(related_errors),
+            root_cause=self.identify_root_cause(related_errors),
+            impact_scope=self.calculate_impact(related_errors),
+        )
+
+
+class CrossSystemCorrelator:
+    """Correlate errors across different systems using correlation IDs."""
+
+    def __init__(self, analyzer: ErrorPatternAnalyzer | None = None) -> None:
+        self.analyzer = analyzer or ErrorPatternAnalyzer()
+
+    def correlate_distributed_errors(self, correlation_id: str) -> List[ErrorEvent]:
+        return self.analyzer.get_correlated_errors(correlation_id)
+
+    def collect_all_events(self, correlation_id: str) -> List[ErrorEvent]:
+        return self.analyzer.get_correlated_errors(correlation_id)
+
+    def build_error_timeline(self, correlation_id: str) -> List[ErrorEvent]:
+        events = self.collect_all_events(correlation_id)
+        return sorted(events, key=lambda x: x.timestamp)
diff --git a/streamlit_extension/utils/correlation_logger.py b/streamlit_extension/utils/correlation_logger.py
new file mode 100644
index 0000000000000000000000000000000000000000..03bdacf67a93c43125bc48e5bb7f1e0a0edf6aee
--- /dev/null
+++ b/streamlit_extension/utils/correlation_logger.py
@@ -0,0 +1,49 @@
+"""Correlation-aware structured logging."""
+
+from __future__ import annotations
+
+import logging
+from datetime import datetime
+from typing import Any, Dict, List, Optional
+
+from ..middleware.context_manager import UserContext
+from .enhanced_recovery import RecoveryResult
+
+
+class CorrelationLogger:
+    """Log errors with correlation and context information."""
+
+    def __init__(self, logger: Optional[logging.Logger] = None) -> None:
+        self.structured_logger = logger or logging.getLogger("correlation")
+
+    def build_error_chain(self, error: Exception) -> List[str]:
+        chain: List[str] = []
+        current = error
+        while current is not None:
+            chain.append(type(current).__name__)
+            current = current.__cause__
+        return chain
+
+    def trace_user_journey(self, context: UserContext) -> Dict[str, Any]:
+        return {"user_id": context.user_id, "session_id": context.session_id}
+
+    def capture_system_state(self) -> Dict[str, Any]:
+        return {"timestamp": datetime.utcnow().isoformat()}
+
+    def log_recovery_actions(self, recovery_result: Optional[RecoveryResult]) -> Dict[str, Any]:
+        if recovery_result is None:
+            return {}
+        return {"success": recovery_result.success}
+
+    def log_error_with_correlation(
+        self, error: Exception, context: UserContext, recovery_result: Optional[RecoveryResult] = None
+    ) -> Dict[str, Any]:
+        log_entry = {
+            "correlation_id": context.correlation_id,
+            "error_chain": self.build_error_chain(error),
+            "user_journey": self.trace_user_journey(context),
+            "system_state": self.capture_system_state(),
+            "recovery_actions": self.log_recovery_actions(recovery_result),
+        }
+        self.structured_logger.error(log_entry)
+        return log_entry
diff --git a/streamlit_extension/utils/enhanced_recovery.py b/streamlit_extension/utils/enhanced_recovery.py
new file mode 100644
index 0000000000000000000000000000000000000000..9f9f42bd843bb73703ad7f4a78b7bb5df181c99a
--- /dev/null
+++ b/streamlit_extension/utils/enhanced_recovery.py
@@ -0,0 +1,108 @@
+"""Enhanced error recovery strategies."""
+
+from __future__ import annotations
+
+import time
+from abc import ABC, abstractmethod
+from dataclasses import dataclass
+from typing import Any, List, Optional
+
+from ..middleware.context_manager import UserContext
+
+
+# Custom exception types used in recovery strategies
+class OperationalError(Exception):
+    """Simulate database operational error."""
+
+
+class AuthenticationError(Exception):
+    """Simulate authentication error."""
+
+
+class ValidationError(Exception):
+    """Simulate validation error."""
+
+
+@dataclass
+class RecoveryResult:
+    success: bool
+    result: Optional[Any] = None
+    fallback: Optional[Any] = None
+
+
+class RecoveryStrategy(ABC):
+    """Interface for recovery strategies."""
+
+    @abstractmethod
+    def can_recover(self, error: Exception, context: UserContext) -> bool:
+        ...
+
+    @abstractmethod
+    def attempt_recovery(self, error: Exception, context: UserContext) -> RecoveryResult:
+        ...
+
+    @abstractmethod
+    def get_fallback(self, error: Exception, context: UserContext) -> Any:
+        ...
+
+
+class DatabaseRecoveryStrategy(RecoveryStrategy):
+    def can_recover(self, error: Exception, context: UserContext) -> bool:
+        return isinstance(error, OperationalError)
+
+    def attempt_recovery(self, error: Exception, context: UserContext) -> RecoveryResult:
+        if not self.can_recover(error, context):
+            return RecoveryResult(False)
+        time.sleep(0.01)  # Simulate retry delay
+        return RecoveryResult(True, result="db_recovered")
+
+    def get_fallback(self, error: Exception, context: UserContext) -> Any:
+        return "db_fallback"
+
+
+class AuthenticationRecoveryStrategy(RecoveryStrategy):
+    def can_recover(self, error: Exception, context: UserContext) -> bool:
+        return isinstance(error, AuthenticationError)
+
+    def attempt_recovery(self, error: Exception, context: UserContext) -> RecoveryResult:
+        if not self.can_recover(error, context):
+            return RecoveryResult(False)
+        if context.user_id:
+            return RecoveryResult(True, result="auth_recovered")
+        return RecoveryResult(False, fallback="guest")
+
+    def get_fallback(self, error: Exception, context: UserContext) -> Any:
+        return "guest"
+
+
+class ValidationRecoveryStrategy(RecoveryStrategy):
+    def can_recover(self, error: Exception, context: UserContext) -> bool:
+        return isinstance(error, ValidationError)
+
+    def attempt_recovery(self, error: Exception, context: UserContext) -> RecoveryResult:
+        if not self.can_recover(error, context):
+            return RecoveryResult(False)
+        return RecoveryResult(True, result="validated")
+
+    def get_fallback(self, error: Exception, context: UserContext) -> Any:
+        return "validation_fallback"
+
+
+class RecoveryEngine:
+    """Engine that orchestrates multiple recovery strategies."""
+
+    def __init__(self, strategies: Optional[List[RecoveryStrategy]] = None) -> None:
+        self.strategies = strategies or []
+
+    def register_strategy(self, strategy: RecoveryStrategy) -> None:
+        self.strategies.append(strategy)
+
+    def attempt_recovery(self, error: Exception, context: UserContext) -> RecoveryResult:
+        for strategy in self.strategies:
+            if strategy.can_recover(error, context):
+                result = strategy.attempt_recovery(error, context)
+                if result.success:
+                    return result
+                fallback = strategy.get_fallback(error, context)
+                return RecoveryResult(False, fallback=fallback)
+        return RecoveryResult(False)
diff --git a/streamlit_extension/utils/error_analytics.py b/streamlit_extension/utils/error_analytics.py
new file mode 100644
index 0000000000000000000000000000000000000000..0780f48af5b97173249ade3b7afd6fc79a9db2e6
--- /dev/null
+++ b/streamlit_extension/utils/error_analytics.py
@@ -0,0 +1,57 @@
+"""Simple error analytics engine."""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import timedelta
+from typing import Any, Dict, List, Tuple
+
+from ..middleware.context_manager import UserContext
+
+
+@dataclass
+class ErrorInsights:
+    error_trends: Dict[str, Any]
+    pattern_detection: Dict[str, Any]
+    recovery_effectiveness: float
+    user_impact: int
+    system_health: str
+    recommendations: List[str]
+
+
+class ErrorAnalyticsEngine:
+    """Collect basic error statistics and generate insights."""
+
+    def __init__(self) -> None:
+        self.errors: List[Tuple[Exception, UserContext, str]] = []
+
+    def record_error(self, error: Exception, context: UserContext, correlation_id: str) -> None:
+        self.errors.append((error, context, correlation_id))
+
+    def analyze_error_trends(self, time_window: timedelta) -> Dict[str, Any]:
+        return {"total": len(self.errors)}
+
+    def detect_error_patterns(self, time_window: timedelta) -> Dict[str, Any]:
+        return {}
+
+    def analyze_recovery_success(self, time_window: timedelta) -> float:
+        return 1.0
+
+    def calculate_user_impact(self, time_window: timedelta) -> int:
+        return len(self.errors)
+
+    def assess_system_health(self, time_window: timedelta) -> str:
+        return "good" if not self.errors else "degraded"
+
+    def generate_recommendations(self) -> List[str]:
+        return []
+
+    def generate_error_insights(self, time_window: timedelta) -> ErrorInsights:
+        return ErrorInsights(
+            error_trends=self.analyze_error_trends(time_window),
+            pattern_detection=self.detect_error_patterns(time_window),
+            recovery_effectiveness=self.analyze_recovery_success(time_window),
+            user_impact=self.calculate_user_impact(time_window),
+            system_health=self.assess_system_health(time_window),
+            recommendations=self.generate_recommendations(),
+        )
diff --git a/tests/test_correlation_system.py b/tests/test_correlation_system.py
new file mode 100644
index 0000000000000000000000000000000000000000..0fc6ff87e6c8b0fc525e64d4a5176eae59572498
--- /dev/null
+++ b/tests/test_correlation_system.py
@@ -0,0 +1,51 @@
+import threading
+import sys
+import pathlib
+
+sys.path.append(str(pathlib.Path(__file__).resolve().parents[1]))
+
+from streamlit_extension.middleware.correlation import (
+    CorrelationManager,
+    RequestLifecycleTracker,
+)
+from streamlit_extension.middleware.context_manager import ContextManager, ContextMiddleware
+
+
+def test_correlation_id_propagation():
+    manager = CorrelationManager()
+    cid = manager.get_or_create()
+    assert manager.get_correlation_id() == cid
+
+
+def test_cross_request_correlation():
+    manager = CorrelationManager()
+    tracker = RequestLifecycleTracker()
+    context_mgr = ContextManager(manager)
+    middleware = ContextMiddleware(context_mgr, tracker)
+
+    middleware.process_request({"session_id": "s1"})
+    cid1 = context_mgr.get_context().correlation_id
+    middleware.process_response({"status": "ok"})
+
+    middleware.process_request({"session_id": "s2"})
+    cid2 = context_mgr.get_context().correlation_id
+    middleware.process_response({"status": "ok"})
+
+    assert cid1 != cid2
+    assert len(tracker.events) == 4  # start/end for two requests
+
+
+def test_correlation_in_async_operations():
+    manager = CorrelationManager()
+    results = []
+
+    def worker():
+        results.append(manager.get_or_create())
+
+    threads = [threading.Thread(target=worker) for _ in range(2)]
+    for t in threads:
+        t.start()
+    for t in threads:
+        t.join()
+
+    assert len(set(results)) == 2
diff --git a/tests/test_enhanced_recovery.py b/tests/test_enhanced_recovery.py
new file mode 100644
index 0000000000000000000000000000000000000000..f346283a333c9ce04cd8e25194f0eb980e42ff77
--- /dev/null
+++ b/tests/test_enhanced_recovery.py
@@ -0,0 +1,56 @@
+from datetime import datetime
+import time
+import sys
+import pathlib
+
+sys.path.append(str(pathlib.Path(__file__).resolve().parents[1]))
+
+from streamlit_extension.middleware.context_manager import UserContext
+from streamlit_extension.utils.enhanced_recovery import (
+    AuthenticationError,
+    AuthenticationRecoveryStrategy,
+    DatabaseRecoveryStrategy,
+    OperationalError,
+    RecoveryEngine,
+    ValidationError,
+    ValidationRecoveryStrategy,
+)
+
+
+def create_context(user_id: str = "user") -> UserContext:
+    return UserContext(
+        user_id=user_id,
+        session_id="sess",
+        request_id="req",
+        correlation_id="cid",
+        ip_address="0.0.0.0",
+        user_agent="test",
+        timestamp=datetime.now(),
+        permissions=[],
+        preferences={},
+        performance_budget={},
+    )
+
+
+def test_multi_strategy_recovery() -> None:
+    engine = RecoveryEngine([DatabaseRecoveryStrategy(), ValidationRecoveryStrategy()])
+    context = create_context()
+    result = engine.attempt_recovery(ValidationError("bad"), context)
+    assert result.success and result.result == "validated"
+
+
+def test_context_aware_recovery() -> None:
+    engine = RecoveryEngine([AuthenticationRecoveryStrategy()])
+    context = create_context(user_id="user123")
+    result = engine.attempt_recovery(AuthenticationError("auth"), context)
+    assert result.success and result.result == "auth_recovered"
+
+
+def test_recovery_performance_impact() -> None:
+    engine = RecoveryEngine([DatabaseRecoveryStrategy()])
+    context = create_context()
+    start = time.time()
+    engine.attempt_recovery(OperationalError("db"), context)
+    duration = time.time() - start
+    assert duration < 0.5
+
 
EOF
)